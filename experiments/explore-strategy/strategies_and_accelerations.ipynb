{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "EXPERIMENT_PATH = f\"{ROOT_PATH}/experiments/exploration-strategy\"\n",
    "sys.path.insert(0, ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load, dumps, dump\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from src.datasets.oracle import Oracle, OracleRequest, TIMEOUT\n",
    "from src.datasets.data_config import HINTSETS, DOPS, HINTS, DEFAULT_HINTSET\n",
    "from src.utils import get_full_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_oracles = {\n",
    "    \"JOB\": Oracle(f\"{ROOT_PATH}/data/processed/JOB\"),\n",
    "    \"tpch_10gb\": Oracle(f\"{ROOT_PATH}/data/processed/tpch_10gb\"),\n",
    "    \"sample_queries\": Oracle(f\"{ROOT_PATH}/data/processed/sample_queries\"),\n",
    "}\n",
    "\n",
    "bench_to_title = {\n",
    "    \"JOB\": \"JOB\",\n",
    "    \"sample_queries\": \"SQ\",\n",
    "    \"tpch_10gb\": \"TPCH\"\n",
    "}\n",
    "\n",
    "DEFAULT_DOP = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the vastness of the search space, even with boolean hints ($2^{\\# \\text{hintsets}}$), and our desire to manage the degree of parallelism (`DOP` value), we are compelled to find ways to reduce the search space. \n",
    "\n",
    "Initially, a **greedy algorithm** was considered, which sequentially disables hintsets. However, it was observed in practice that disabling a single operation is sometimes insufficient to achieve the desired result (if the planner considers $op_1 < op_2 < op_3$, we cannot make it use $op_3$ by simply disabling only one operation). This led to the decision to implement actions such as \"disable all joins except one,\" making the search algorithm resemble a local search approach.\n",
    "\n",
    "Since it is not predetermined which actions are most promising, we **parameterize** the general algorithm scheme and **empirically determine the best combinations of actions**. It is evident that the more actions we add, the more extensively we will explore, thereby potentially finding better solutions, but at the cost of increased search expenses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution state (`SearchingState`) during the search is described by only two parameters - the set of disabled operations (`hintset`) and the chosen degree of parallelism (`dop`). \n",
    "\n",
    "The neighborhood of the solution is defined by search parameters (`SearchingSettings`). I will write more about what exactly each of them does somewhere else ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFF_INL_HINT = 64 | 8 | 2\n",
    "N_SCANS = 4\n",
    "N_JOINS = 3\n",
    "NL_POS = 2\n",
    "assert N_SCANS + N_JOINS == len(HINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SearchingState` and `SearchingSettings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchingState = namedtuple(\n",
    "    \"SearchingState\", \n",
    "    [\"dop\", \"hintset\"], \n",
    "    defaults=[DEFAULT_DOP, DEFAULT_HINTSET]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SearchingSettings = namedtuple(\n",
    "    \"SearchingSettings\", \n",
    "    [\n",
    "        \"disable_ops\",\n",
    "        \"decrease_dop\", \n",
    "        \"disable_inl\",\n",
    "        \"boost_threshold\", \n",
    "        \"max_iter\", \n",
    "        \"avoid_duplicates\",\n",
    "        \"use_timeout\",\n",
    "        \"use_joined_search\",\n",
    "        \"prioritize_neighbors\",\n",
    "        \"force_join\",\n",
    "        \"force_only_nl\",\n",
    "    ],\n",
    "    defaults=[\n",
    "        False, \n",
    "        False, \n",
    "        False, \n",
    "        1.0, \n",
    "        0,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "    ]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_pool = []\n",
    "for disable_ops in [False, True]:\n",
    "    for decrease_dop in [False, True]:\n",
    "        for disable_inl in [False, True]:\n",
    "            for max_iter in [1, 2, float(\"inf\")]:\n",
    "                for boost_threshold in [1.0, 1.1, 1.2, 1.5, 2.0]:   \n",
    "                    for use_timeout in [False, True]:\n",
    "                        for avoid_duplicates in [False, True]:\n",
    "                            for use_joined_search in [False, True]:\n",
    "                                for prioritize_neighbors in [False, True]:\n",
    "                                    for force_join in [False, True]:\n",
    "                                        for force_only_nl in [False, True]:\n",
    "                                            settings = SearchingSettings(\n",
    "                                                disable_ops=disable_ops,\n",
    "                                                decrease_dop=decrease_dop, \n",
    "                                                disable_inl=disable_inl, \n",
    "                                                boost_threshold=boost_threshold,\n",
    "                                                max_iter=max_iter,\n",
    "                                                use_timeout=use_timeout,\n",
    "                                                avoid_duplicates=avoid_duplicates,\n",
    "                                                use_joined_search=use_joined_search,\n",
    "                                                prioritize_neighbors=prioritize_neighbors,\n",
    "                                                force_join=force_join,\n",
    "                                                force_only_nl=force_only_nl,\n",
    "                                            )\n",
    "                                            settings_pool.append(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE NUMBER OF ALL SEARCHING SETTINGS IS 7680\n"
     ]
    }
   ],
   "source": [
    "print(f\"THE NUMBER OF ALL SEARCHING SETTINGS IS {len(settings_pool)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QueryExplorer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is some wrapper over the `oracle` for a specific query and specific settings `SearchingSettings` parameters. Its purpose is to perform local search according to the selected settings while managing the total execution time, number of planning, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExplorer:\n",
    "    def __init__(self, query_name, oracle, settings=SearchingSettings()):\n",
    "        self.oracle = oracle\n",
    "        self.query_name = query_name\n",
    "        self.settings = settings\n",
    "\n",
    "        self.learning_time = 0\n",
    "        self.n_executions = 0\n",
    "        self.n_plannings = 0\n",
    "\n",
    "        self.default_plan = None\n",
    "        self.explored_plans = set()\n",
    "        self.explored_states = set()\n",
    "\n",
    "        self._warmup()\n",
    "\n",
    "    def _warmup(self):\n",
    "        def_request = OracleRequest(query_name=self.query_name, dop=DEFAULT_DOP, hintset=DEFAULT_HINTSET)\n",
    "        def_state = SearchingState()\n",
    "\n",
    "        ex_time = self.oracle.get_execution_time(request=def_request)\n",
    "        plan_time = self.oracle.get_planning_time(request=def_request)  \n",
    "        plan = self.get_plan(state=def_state, bypass=True)\n",
    "\n",
    "        self.default_time = ex_time + plan_time\n",
    "        self.learning_time += ex_time + plan_time\n",
    "        self.default_plan = plan \n",
    "        self.explored_plans.add(plan)\n",
    "        self.explored_states.add(def_state)\n",
    "        self.n_executions += 1\n",
    "\n",
    "    def explore_state(self, state, timeout=None, bypass=False):\n",
    "        if not self.settings.use_timeout or timeout is None:\n",
    "            timeout = 2 * self.default_time\n",
    "\n",
    "        request = OracleRequest(query_name=self.query_name, dop=state.dop, hintset=state.hintset)\n",
    "        ex_time = self.oracle.get_execution_time(request=request)\n",
    "        plan_time = self.oracle.get_planning_time(request=request)\n",
    "        e2e_time = min(timeout, ex_time + plan_time)\n",
    "\n",
    "        if not bypass:\n",
    "            self.learning_time += e2e_time\n",
    "            self.explored_plans.add(self.get_plan(state=state, bypass=True))\n",
    "            self.explored_states.add(state)\n",
    "            self.n_executions += 1\n",
    "            \n",
    "        return e2e_time\n",
    "\n",
    "    def get_plan(self, state, bypass=True):\n",
    "        plan = get_full_plan(\n",
    "            query_name=self.query_name, \n",
    "            oracle=self.oracle,\n",
    "            dop=state.dop,\n",
    "            hintset=state.hintset\n",
    "        )\n",
    "        request = OracleRequest(query_name=self.query_name, dop=state.dop, hintset=state.hintset)\n",
    "        if not bypass:\n",
    "            self.learning_time += self.oracle.get_planning_time(request=request)\n",
    "            self.n_plannings += 1\n",
    "\n",
    "        return plan\n",
    "\n",
    "    def get_ex_time(self, dop, hintset):\n",
    "        request = OracleRequest(query_name=self.query_name, dop=dop, hintset=hintset)\n",
    "        return self.oracle.get_execution_time(request=request)\n",
    "\n",
    "    def run(self):\n",
    "        prev_state = None\n",
    "        \n",
    "        plan_to_ex_time = defaultdict(float)\n",
    "        plan_to_ex_time[self.default_plan] = self.get_ex_time(dop=DEFAULT_DOP, hintset=DEFAULT_HINTSET)\n",
    "\n",
    "        record_state = SearchingState()\n",
    "        record_time = self.default_time\n",
    "\n",
    "        it = 0\n",
    "        while it < self.settings.max_iter:\n",
    "            timeout = record_time/self.settings.boost_threshold\n",
    "\n",
    "            prev_state = record_state\n",
    "            neighbors = filter(lambda st: st not in self.explored_states, self.get_neighbors(state=record_state))\n",
    "            \n",
    "            if self.settings.prioritize_neighbors:\n",
    "                neighbors = sorted(neighbors, key=lambda st: self.explore_state(state=st, bypass=True))\n",
    "            \n",
    "            for ngb_state in neighbors:\n",
    "                if self.settings.avoid_duplicates:\n",
    "                    ngb_plan = self.get_plan(state=ngb_state)\n",
    "                    if ngb_plan in plan_to_ex_time: \n",
    "                        ngb_time = self.explore_state(state=ngb_state, timeout=timeout, bypass=True)\n",
    "                    else:\n",
    "                        ngb_time = self.explore_state(state=ngb_state, timeout=timeout)\n",
    "                        plan_to_ex_time[ngb_plan] = self.get_ex_time(dop=ngb_state.dop, hintset=ngb_state.hintset) \n",
    "                else:\n",
    "                    ngb_time = self.explore_state(state=ngb_state, timeout=timeout)\n",
    "                \n",
    "                if record_time / ngb_time > self.settings.boost_threshold:\n",
    "                    record_state, record_time = ngb_state, ngb_time\n",
    "                    if self.settings.prioritize_neighbors:\n",
    "                        break\n",
    "            \n",
    "            it += 1\n",
    "            if prev_state == record_state:\n",
    "                break  \n",
    "            \n",
    "        return record_state\n",
    "\n",
    "    def get_neighbors(self, state):\n",
    "        current_dop, current_hintset = state.dop, state.hintset\n",
    "        neighbors = set()\n",
    "\n",
    "        if self.settings.use_joined_search:\n",
    "            to_try_dops = DOPS\n",
    "        else:\n",
    "            to_try_dops = [current_dop]\n",
    "        \n",
    "        for dop in to_try_dops:\n",
    "            if self.settings.disable_ops:\n",
    "                for op_num in range(len(HINTS)):\n",
    "                    neighbors.add(SearchingState(dop=dop, hintset=current_hintset | (1 << op_num)))\n",
    "\n",
    "            if self.settings.disable_inl:\n",
    "                neighbors.add(SearchingState(dop=dop, hintset=current_hintset | (OFF_INL_HINT)))\n",
    "\n",
    "            if self.settings.decrease_dop:\n",
    "                for new_dop in [new_dop for new_dop in DOPS if new_dop < dop]:\n",
    "                    neighbors.add(SearchingState(dop=new_dop, hintset=current_hintset))                    \n",
    "            \n",
    "            if self.settings.force_join:\n",
    "                for join_num in range(N_JOINS):\n",
    "                    saved_scans = ((1 << N_SCANS) - 1) & current_hintset\n",
    "                    only_one_join = (((1 << N_JOINS) - 1) - (1 << join_num)) << N_SCANS\n",
    "                    neighbors.add(SearchingState(dop=dop, hintset=only_one_join|saved_scans))\n",
    "\n",
    "            if self.settings.force_only_nl:\n",
    "                join_num = NL_POS\n",
    "                saved_scans = ((1 << N_SCANS) - 1) & current_hintset\n",
    "                only_one_join = (((1 << N_JOINS) - 1) - (1 << join_num)) << N_SCANS\n",
    "                neighbors.add(SearchingState(dop=dop, hintset=only_one_join|saved_scans))                    \n",
    "\n",
    "        return neighbors        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - collecting info for each settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7680/7680 [06:26<00:00, 19.85it/s]\n"
     ]
    }
   ],
   "source": [
    "e2e_times = defaultdict(dict)\n",
    "learning_times = defaultdict(dict)\n",
    "\n",
    "for settings in tqdm(settings_pool):\n",
    "    \n",
    "    for bench_name, oracle in cached_oracles.items():\n",
    "        e2e_time, learning_time = 0, 0\n",
    "\n",
    "        for query_name in oracle.get_query_names():\n",
    "            explorer = QueryExplorer(query_name=query_name, oracle=oracle, settings=settings)\n",
    "            dop, hintset = explorer.run()\n",
    "            learning_time += explorer.learning_time\n",
    "            request = OracleRequest(query_name=query_name, hintset=hintset, dop=dop)\n",
    "            e2e_time += oracle.get_execution_time(request) + oracle.get_planning_time(request)\n",
    "        \n",
    "        e2e_times[bench_name][settings] = round(e2e_time/1000, 3)\n",
    "        learning_times[bench_name][settings] = round(learning_time/1000, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - collecting info for baseline and ideal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_e2e_times = {}\n",
    "def_times = {}\n",
    "\n",
    "all_states = [SearchingState(dop, hintset) for dop in DOPS for hintset in HINTSETS]\n",
    "\n",
    "for bench_name, oracle in cached_oracles.items():\n",
    "    best_e2e_time, def_time = 0, 0\n",
    "    for query_name in oracle.get_query_names():\n",
    "        explorer = QueryExplorer(query_name=query_name, oracle=oracle, settings=settings)\n",
    "        best_state = min(all_states, key=lambda st: explorer.explore_state(st))\n",
    "        best_dop, best_hintset = best_state.dop, best_state.hintset\n",
    "\n",
    "        best_request = OracleRequest(query_name=query_name, hintset=best_hintset, dop=best_dop)\n",
    "        best_e2e_time += oracle.get_execution_time(best_request) + oracle.get_planning_time(best_request)\n",
    "\n",
    "        def_request = OracleRequest(query_name=query_name, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP)\n",
    "        def_time += oracle.get_execution_time(def_request) + oracle.get_planning_time(def_request)\n",
    "\n",
    "    best_e2e_times[bench_name] = round(best_e2e_time / 1000, 3)\n",
    "    def_times[bench_name] = round(def_time / 1000, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Which moves are the most important to get high boost*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze results for `JOB` benchmark and just provide info for the rest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_settings(descr, bench_name, settings):\n",
    "    e2e_time = e2e_times[bench_name][settings]\n",
    "    boost = def_times[bench_name] - e2e_times[bench_name][settings]\n",
    "    max_boost = def_times[bench_name] - best_e2e_times[bench_name]\n",
    "    print(f\"| {descr} | {100 * boost/max_boost:0.1f} % | {learning_times[bench_name][settings]:0.2f} s |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_name = \"tpch_10gb\"\n",
    "MAX_ITER = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| `DISABLE_OP` | 91.2 % | 7611.98 s |\n",
      "| `DISABLE_INL` | 29.8 % | 1175.42 s |\n",
      "| `FORCE_JOIN` | 65.5 % | 2051.35 s |\n",
      "| `DECREASE_DOP` | 22.0 % | 1527.04 s |\n",
      "| `DISABLE_OP` OR `DECREASE_DOP` | 99.3 % | 11913.05 s |\n",
      "| `DISABLE_INL` OR `DECREASE_DOP` | 50.1 % | 2814.50 s |\n",
      "| `FORCE_JOIN` OR `DECREASE_DOP` | 73.4 % | 4408.37 s |\n",
      "| (`FORCE_JOIN` OR `DISABLE_INL`  OR `DECREASE_DOP`) | 76.5 % | 6059.70 s |\n",
      "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) | 99.7 % | 16546.93 s |\n",
      "| `DISABLE_OP` AND `CHANGE_DOP` | 100.0 % | 24994.40 s |\n",
      "| `DISABLE_INL` AND `CHANGE_DOP` | 46.3 % | 2545.40 s |\n",
      "| `FORCE_JOIN` AND `CHANGE_DOP` | 75.2 % | 5118.48 s |\n",
      "| (`FORCE_JOIN` OR `DISABLE_INL`) AND `CHANGE_DOP` | 78.4 % | 9478.47 s |\n",
      "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) AND `CHANGE_DOP` | 100.0 % | 34287.37 s |\n"
     ]
    }
   ],
   "source": [
    "settings_and_descr = [\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_ops=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`DISABLE_OP`\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_inl=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`DISABLE_INL`\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`FORCE_JOIN`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            decrease_dop=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`DECREASE_DOP`\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_ops=True, \n",
    "            decrease_dop=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`DISABLE_OP` OR `DECREASE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_inl=True, \n",
    "            decrease_dop=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ), \n",
    "        \"`DISABLE_INL` OR `DECREASE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            decrease_dop=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"`FORCE_JOIN` OR `DECREASE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            disable_inl=True, \n",
    "            decrease_dop=True,\n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"(`FORCE_JOIN` OR `DISABLE_INL`  OR `DECREASE_DOP`)\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            disable_inl=True, \n",
    "            disable_ops=True, \n",
    "            decrease_dop=True,\n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"(`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`)\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_ops=True, \n",
    "            use_joined_search=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"`DISABLE_OP` AND `CHANGE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            disable_inl=True, \n",
    "            use_joined_search=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"`DISABLE_INL` AND `CHANGE_DOP`\",\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            use_joined_search=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"`FORCE_JOIN` AND `CHANGE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            disable_inl=True, \n",
    "            use_joined_search=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"(`FORCE_JOIN` OR `DISABLE_INL`) AND `CHANGE_DOP`\"\n",
    "    ),\n",
    "\n",
    "    (\n",
    "        SearchingSettings(\n",
    "            force_join=True, \n",
    "            disable_inl=True, \n",
    "            disable_ops=True, \n",
    "            decrease_dop=True,\n",
    "            use_joined_search=True, \n",
    "            max_iter=MAX_ITER\n",
    "        ),\n",
    "        \"(`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) AND `CHANGE_DOP`\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for settings, descr in settings_and_descr:\n",
    "    evaluate_settings(descr, bench_name, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that limiting operations on `JOB` alone can achieve only `69%` of the maximum boost. Moreover, even utilizing a local search procedure to explore all neighborhoods requires about `10,000` seconds (~`x20` the execution time of the benchmark). By both restricting operations and adjusting the degree of parallelism, we can reach around `78%`. Further gains necessitate the use of specific join-related hints. Employing both `OFF_INL` and `FORCE_JOIN` can elevate this to `92%`. However, approaching the optimum necessitates simultaneously altering joins along with `DOP`s. Unfortunately, this proves to be an extremely costly operation — a complete investigation in this mode takes about `38,000` seconds, considering the use of T/O for long queries.\n",
    "\n",
    "At the same time, simply trying one action such as a) reducing the degree of parallelism, b) allowing only one join, or c) turning off `INL` can achieve ~ `40%`. Considering that this **only requires exploration 1-3 neighbors**, it's an exceptionally good result. The main observation, however, is that only by altering joins (`NO_INL`, `FORCE_JOIN`) together with adjusting the degree of parallelism, can one reach `94%`! And this in just `12,000` seconds compared to `38,000` for a full exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `JOB`\n",
    "\n",
    "| `SearchingSetting` | Boost (% of optimal) | Learning Time (s) |\n",
    "|-|-|-|\n",
    "| `DISABLE_OP` | 69.2 % | 10149.92 s |\n",
    "| `DISABLE_INL` | 38.0 % | 1115.87 s |\n",
    "| `FORCE_JOIN` | 52.2 % | 1911.83 s |\n",
    "| `DECREASE_DOP` | 40.8 % | 1514.32 s |\n",
    "| `DISABLE_OP` OR `DECREASE_DOP` | 78.1 % | 13114.70 s |\n",
    "| `DISABLE_INL` OR `DECREASE_DOP` | 74.6 % | 2951.83 s |\n",
    "| `FORCE_JOIN` OR `DECREASE_DOP` | 66.2 % | 4340.27 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`  OR `DECREASE_DOP`) | **87.9 %** | **7374.47 s** |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) | 91.5 % | 17072.23 s |\n",
    "| `DISABLE_OP` AND `CHANGE_DOP` | 82.2 % | 30877.65 s |\n",
    "| `DISABLE_INL` AND `CHANGE_DOP` | 71.6 % | 2423.74 s |\n",
    "| `FORCE_JOIN` AND `CHANGE_DOP` | 66.3 % | 4780.83 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`) AND `CHANGE_DOP` | **94.2 %** | **12112.15 s** |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) AND `CHANGE_DOP` | 98.5 % | 37748.68 s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sample_queries`\n",
    "\n",
    "| `SearchingSetting` | Boost (% of optimal) | Learning Time (s) |\n",
    "|-|-|-|\n",
    "| `DISABLE_OP` | 85.4 % | 12914.35 s |\n",
    "| `DISABLE_INL` | 40.5 % | 1603.38 s |\n",
    "| `FORCE_JOIN` | 74.5 % | 2751.21 s |\n",
    "| `DECREASE_DOP` | 49.4 % | 2151.14 s |\n",
    "| `DISABLE_OP` OR `DECREASE_DOP` | 88.2 % | 16663.09 s |\n",
    "| `DISABLE_INL` OR `DECREASE_DOP` | 75.4 % | 3951.95 s |\n",
    "| `FORCE_JOIN` OR `DECREASE_DOP` | 79.3 % | 6052.97 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`  OR `DECREASE_DOP`) | 85.3 % | 9715.47 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) | 93.5 % | 20437.88 s |\n",
    "| `DISABLE_OP` AND `CHANGE_DOP` | 93.0 % | 33940.96 s |\n",
    "| `DISABLE_INL` AND `CHANGE_DOP` | 59.9 % | 3084.41 s |\n",
    "| `FORCE_JOIN` AND `CHANGE_DOP` | 82.6 % | 6626.23 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`) AND `CHANGE_DOP` | **88.0 %** | **13185.60 s** |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) AND `CHANGE_DOP` | 95.0 % | 44233.18 s |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TPCH`\n",
    "\n",
    "| `SearchingSetting` | Boost (% of optimal) | Learning Time (s) |\n",
    "|-|-|-|\n",
    "| `DISABLE_OP` | **91.2 %** | **7611.98 s** |\n",
    "| `DISABLE_INL` | 29.8 % | 1175.42 s |\n",
    "| `FORCE_JOIN` | **65.5 %** | **2051.35 s** |\n",
    "| `DECREASE_DOP` | 22.0 % | 1527.04 s |\n",
    "| `DISABLE_OP` OR `DECREASE_DOP` | **99.3 %** | **11913.05 s** |\n",
    "| `DISABLE_INL` OR `DECREASE_DOP` | 50.1 % | 2814.50 s |\n",
    "| `FORCE_JOIN` OR `DECREASE_DOP` | 73.4 % | 4408.37 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`  OR `DECREASE_DOP`) | 76.5 % | 6059.70 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) | 99.7 % | 16546.93 s |\n",
    "| `DISABLE_OP` AND `CHANGE_DOP` | 100.0 % | 24994.40 s |\n",
    "| `DISABLE_INL` AND `CHANGE_DOP` | 46.3 % | 2545.40 s |\n",
    "| `FORCE_JOIN` AND `CHANGE_DOP` | 75.2 % | 5118.48 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL`) AND `CHANGE_DOP` | 78.4 % | 9478.47 s |\n",
    "| (`FORCE_JOIN` OR `DISABLE_INL` OR `DISABLE_OP` OR `DECREASE_DOP`) AND `CHANGE_DOP` | 100.0 % | 34287.37 s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Do we really need to explore all of neighbors?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the semantics of `SearchingState`, it is clear that the outcomes of exploring a state depend solely on the plan they lead to. Thus, executing the same plan twice is unnecessary.\n",
    "\n",
    "However, in practice, we have observed an interesting phenomenon: although two different states may lead to the same plan (which obviously will execute for the same amount of time), the planning time can vary significantly! Sometimes it may be beneficial to use hints (or change the level of parallelism) simply to reduce the planning time.\n",
    "\n",
    "Let's verify this in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_info_about_plans(bench_name):\n",
    "    oracle = cached_oracles[bench_name]\n",
    "    for query_name in oracle.get_query_names():\n",
    "        for hintset in HINTSETS:\n",
    "            for dop in DOPS:\n",
    "                request = OracleRequest(query_name=query_name, hintset=hintset, dop=dop)\n",
    "                planning_time = oracle.get_planning_time(request=request)\n",
    "                ex_time = oracle.get_execution_time(request=request)\n",
    "                if ex_time >= TIMEOUT:\n",
    "                    continue\n",
    "                plan = QueryExplorer(query_name, oracle).get_plan(SearchingState(hintset=hintset, dop=dop))\n",
    "                plan_to_times[plan].append((planning_time, query_name, ex_time, dop, hintset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| `29c` | 2.072s - 8.832s | 0.0s - 0.0s |\n",
      "| `28b` | 0.595s - 8.222s | 2.6s - 2.6s |\n",
      "| `29a` | 0.881s - 12.540s | 0.0s - 0.0s |\n",
      "| `q17_7a164` | 1.114s - 4.547s | 52.6s - 52.6s |\n",
      "| `q17_7a164` | 0.637s - 4.153s | 55.6s - 55.2s |\n",
      "| `q20_24b` | 0.501s - 5.508s | 1.5s - 1.6s |\n"
     ]
    }
   ],
   "source": [
    "for bench_name in [\"JOB\", \"sample_queries\"]:\n",
    "    plan_to_times = defaultdict(list)\n",
    "    collect_info_about_plans(bench_name)\n",
    "\n",
    "    plan_times_ordered_by_deviation = sorted(\n",
    "        plan_to_times.values(), \n",
    "        key=lambda el : max([p_t for p_t, *info in el]) - min([p_t for p_t, *info in el])\n",
    "    )\n",
    "\n",
    "    for plan_times in plan_times_ordered_by_deviation[-3:]:\n",
    "        plan_times = sorted(plan_times)\n",
    "        query_name = plan_times[0][1]\n",
    "        plan_time_info = f\"{plan_times[0][0]/1000:0.3f}s - {plan_times[-1][0]/1000:0.3f}s\"\n",
    "        ex_time_info = f\"{plan_times[0][2]/1000:.1f}s - {plan_times[-1][2]/1000:.1f}s\"\n",
    "        print(f\"| `{query_name}` | {plan_time_info} | {ex_time_info} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Query Name | Planning Times (sec) | Execution Times (sec) |\n",
    "|-|-|-|\n",
    "| `28b` | 0.595s - 8.222s | 2.6s - 2.6s |\n",
    "| `29a` | 0.881s - 12.540s | 0.0s - 0.0s |\n",
    "| `q17_7a164` | 1.114s - 4.547s | 52.6s - 52.6s |\n",
    "| `q17_7a164` | 0.637s - 4.153s | 55.6s - 55.2s |\n",
    "| `q20_24b` | 0.501s - 5.508s | 1.5s - 1.6s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it means, that queries can be speed up to `10x` by simply applying a hint with faster planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_about_plans(bench_name, settings):\n",
    "    oracle = cached_oracles[bench_name]\n",
    "    visited_states = 0\n",
    "    states_with_unique_plans = 0\n",
    "    visited_unique_plans = 0 \n",
    "    all_states = [SearchingState(dop, hintset) for dop in DOPS for hintset in HINTSETS]\n",
    "    for query_name in oracle.get_query_names():\n",
    "        explorer = QueryExplorer(query_name=query_name, oracle=oracle, settings=settings)\n",
    "        dop, hintset = explorer.run()\n",
    "        visited_states += len(set(explorer.explored_states))\n",
    "        visited_unique_plans += len(set(explorer.explored_plans))\n",
    "        states_with_unique_plans += len(set([explorer.get_plan(st) for st in all_states]))\n",
    "        \n",
    "\n",
    "    total_states = len(HINTSETS) * len(DOPS) * len(oracle.get_query_names())\n",
    "\n",
    "    print(f\"| `{bench_to_title[bench_name]}` | {visited_states} / {total_states} | {visited_unique_plans} / {states_with_unique_plans} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| `JOB` | 7980 / 43392 | 2824 / 7692 |\n",
      "| `TPCH` | 1326 / 8448 | 248 / 600 |\n",
      "| `SQ` | 2637 / 15360 | 1366 / 4524 |\n"
     ]
    }
   ],
   "source": [
    "all_moves_settings = SearchingSettings(\n",
    "        force_join=True, \n",
    "        disable_inl=True, \n",
    "        disable_ops=True, \n",
    "        use_joined_search=True, \n",
    "        decrease_dop=True,\n",
    "        max_iter=float(\"inf\")\n",
    ")\n",
    "for bench_name in cached_oracles:\n",
    "    print_summary_about_plans(bench_name, all_moves_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| BENCHMARK | # STATES (VISITED / ALL) | # PLANS (VISITED / ALL) | \n",
    "|-|-|-|\n",
    "| `JOB` | 7980 / 43392 | 2824 / 7692 |\n",
    "| `TPCH` | 1326 / 8448 | 248 / 600 |\n",
    "| `SQ` | 2637 / 15360 | 1366 / 4524 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that local search algorithm significantly reduce search space, but anyway it often executes the same plan several times. This makes no sense, because the execution time does not depend on the hints we recommend, **only the plan matters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Which features are most important to accelerate learning itself*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that a) often very good solutions exist near the initial state, b) the number of unique plans is relatively small, and c) the quality of `SearchingState` is determined solely by the plan, we propose the following techniques to reduce training time:\n",
    "- limit the number of iterations in local search.\n",
    "- pre-plan neighbors and avoid executing the same plans repeatedly.\n",
    "- use timeouts when exploring neighbors (there is no point in waiting for a request to complete if it will take longer than the best known solution).\n",
    "- implement aggressive timeout\n",
    "- use only subset of moves (i.e., consider only a specific part of the neighborhood, for example, limit to just turning off `INL` or decreasing `DOP`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which of these techniques are the most effective, we will introduce a *score* for the search parameters $x$ similar to the F-Score -- this metric balances between the proportion of the boost obtained from the maximum possible acceleration and the proportion of saved training time:\n",
    "\n",
    "\n",
    "$$\\text{score}_{\\beta}(\\text{x}) = F_{\\beta}(\\text{boost\\_coeff}(\\text{x}), \\text{learning\\_coeff}(\\text{x}))$$\n",
    "\n",
    "где $\\text{boost\\_coeff}(\\text{x}) = \\frac{\\text{max\\_possible\\_boost}}{\\text{learning\\_time(x)}}$ и  $\\text{learning\\_coeff}(\\text{x}) = \\frac{\\text{max\\_possible\\_time} - \\text{learning\\_time}(x)}{\\text{max\\_possible\\_time}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different $\\beta$ we will find the best configurations of parameters of the local search algorithm. After that it will become clear which combinations of the proposed techniques are the most useful in each of the cases - 1) when we equally care about both boost and learning time, 2) when we want to get as much boost as possible, and 3) when our research budget is extremely limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_settings(bench_name, condition=None, beta=2):\n",
    "    max_learning_time = max(learning_times[bench_name].values())\n",
    "    max_speedup = def_times[bench_name] - best_e2e_times[bench_name]\n",
    "    best_score, best_settings = float(\"-inf\"), None\n",
    "    \n",
    "    for settings in e2e_times[bench_name]:\n",
    "        if condition and not condition(settings):\n",
    "            continue\n",
    "        \n",
    "        saved_learning_time = max_learning_time - learning_times[bench_name][settings]\n",
    "        learning_coef = saved_learning_time / max_learning_time\n",
    "        boost = def_times[bench_name] - e2e_times[bench_name][settings]\n",
    "        assert boost >= 0\n",
    "        boost_coef = boost / max_speedup\n",
    "        score = (1 + beta ** 2) * learning_coef * boost_coef / (beta ** 2 * learning_coef + boost_coef)\n",
    "        if score > best_score:\n",
    "            best_score, best_settings = score, settings\n",
    "\n",
    "    speedup = def_times[bench_name] - e2e_times[bench_name][best_settings]\n",
    "    speedup_coef = speedup / max_speedup \n",
    "    learning_time = learning_times[bench_name][best_settings]\n",
    "    \n",
    "    best_settings = best_settings._asdict()\n",
    "    def_settings = SearchingSettings()._asdict()\n",
    "    changes = {}\n",
    "    for key in best_settings:\n",
    "        if best_settings[key] != def_settings[key]:\n",
    "            changes[key] = best_settings[key]\n",
    "            \n",
    "    print(f\"BOOST {speedup:0.1f}s ({100 * speedup_coef:0.1f} %) | LEARNED IN {learning_time:0.1f}s\")\n",
    "    print(dumps(changes, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOST 318.2s (55.9 %) | LEARNED IN 1164.3s\n",
      "{\n",
      "    \"boost_threshold\": 1.2,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 403.1s (70.8 %) | LEARNED IN 1846.8s\n",
      "{\n",
      "    \"boost_threshold\": 1.5,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 477.9s (83.9 %) | LEARNED IN 3239.8s\n",
      "{\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 477.9s (83.9 %) | LEARNED IN 3239.8s\n",
      "{\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 477.9s (83.9 %) | LEARNED IN 3239.8s\n",
      "{\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 531.7s (93.3 %) | LEARNED IN 7916.8s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 531.7s (93.3 %) | LEARNED IN 7916.8s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 546.1s (95.9 %) | LEARNED IN 13469.5s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"boost_threshold\": 1.1,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 546.1s (95.9 %) | LEARNED IN 13469.5s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"decrease_dop\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"boost_threshold\": 1.1,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"force_join\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bench_name = \"sample_queries\"\n",
    "condition = lambda el: not el.prioritize_neighbors\n",
    "for beta in [1/10, 1/4, 1/2, 1/1.5, 1, 1.5, 2, 4, 10]:\n",
    "    find_best_settings(bench_name, condition=condition, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General observations:**\n",
    "\n",
    "- with limited training resources, it is advisable to limit to a single iteration of local search and use aggressive timeouts;\n",
    "- avoiding execution same plan multiple times is beneficial across all benchmarks\n",
    "\n",
    "`JOB`:\n",
    "- the greatest performance gain is achieved by managing joins while simultaneously adjusting the `DOP`\n",
    "- disabling of operations turns out to be quite costly — in almost all configurations, it is more advantageous to allocate resources to exploring other aspects (`disable_ops` is `True` only with very high values of $\\beta$)\n",
    "\n",
    "`SQ`:\n",
    "- disabling of operations is extremely costly too, and it is possible to manage with just reducing `DOP` and managing joins\n",
    "\n",
    "`TPCH`:\n",
    "- disabling of operations is not as costly, allowing a rapid achievement of `80%` performance boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *How does the order of neighbor important?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is usually a short path from the initial solution to the suboptimal solution. If we suddenly have some algorithm that will feed us neighbors to check in an optimal order, we can reach the optimum many times faster. Let's see how fast we can approach the optimum if we have some oracle available that sorts the neighbors in the order of their actual execution. If this turns out to be a promising technique, we can try to put the responsibility for this on the neural network - there will be no consequences from incorrect predictions (no regressions, no lost gains), but the potential benefit of correct ordering is obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOST 348.8s (97.2 %) | LEARNED IN 711.3s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 348.8s (97.2 %) | LEARNED IN 711.3s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 348.8s (97.2 %) | LEARNED IN 711.3s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 348.8s (97.2 %) | LEARNED IN 711.3s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 1,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 351.8s (98.1 %) | LEARNED IN 1011.7s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_only_nl\": true\n",
      "}\n",
      "BOOST 352.0s (98.1 %) | LEARNED IN 1045.1s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 352.0s (98.1 %) | LEARNED IN 1045.1s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": 2,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true,\n",
      "    \"force_join\": true\n",
      "}\n",
      "BOOST 353.4s (98.5 %) | LEARNED IN 2100.6s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true\n",
      "}\n",
      "BOOST 353.4s (98.5 %) | LEARNED IN 2100.6s\n",
      "{\n",
      "    \"disable_ops\": true,\n",
      "    \"disable_inl\": true,\n",
      "    \"max_iter\": Infinity,\n",
      "    \"avoid_duplicates\": true,\n",
      "    \"use_timeout\": true,\n",
      "    \"use_joined_search\": true,\n",
      "    \"prioritize_neighbors\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bench_name = \"JOB\"\n",
    "condition = lambda el: el.prioritize_neighbors\n",
    "for beta in [1/10, 1/4, 1/2, 1/1.5, 1, 1.5, 2, 4, 10]:\n",
    "    find_best_settings(bench_name, condition=condition, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that learning can be accelerated many times (or even tens of times). This means that the idea of ranking neighbors through a separate predictive model can be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
