{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "BTCNN_PATH = os.path.join(ROOT_PATH, \"btcnn\")\n",
    "HBO_BENCH_PATH = os.path.join(ROOT_PATH, \"hbo_bench\")\n",
    "\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "sys.path.insert(0, BTCNN_PATH)\n",
    "sys.path.insert(0, HBO_BENCH_PATH)\n",
    "\n",
    "EXPERIMENT_PATH = os.getcwd()\n",
    "ARTIFACTS_PATH = os.path.join(EXPERIMENT_PATH, \"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load, dumps, dump\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hbo_bench.oracle import Oracle, OracleRequest, TIMEOUT\n",
    "from hbo_bench.data_config import HINTSETS, DOPS, HINTS, DEFAULT_HINTSET, DEFAULT_DOP\n",
    "from hbo_bench.utils import get_logical_tree, get_full_plan\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other benchmarks don't have more than 1 query inside one template \n",
    "oracle = Oracle(f\"{HBO_BENCH_PATH}/data/processed/JOB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the template or plan enough to safely estimate the usefullness of hintset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will check the deviations of execution time inside the group of queries under different hintsets.\n",
    "Considered groupping functions are:\n",
    "\n",
    "- query $\\rightarrow$ logical plan, and\n",
    "- query $\\rightarrow$ full plan (i.e. logical plan with estimated cardinalities)\n",
    "\n",
    "For simplicity, we restrict ourselves to groups within which a) a hintset causes some queries to speed up and some to T/O, and b) all queries are sufficiently long (> 1 sec),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_full_plan, get_logical_tree, get_selectivities\n",
    "\n",
    "logical_plan_to_queries = defaultdict(list)\n",
    "full_plan_to_queries = defaultdict(list)\n",
    "\n",
    "for query_name in oracle.get_query_names():\n",
    "    plan = oracle.get_explain_plan(OracleRequest(query_name=query_name, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP))\n",
    "    logical_plan = get_logical_tree(plan)\n",
    "    full_plan = get_full_plan(plan)\n",
    "\n",
    "    logical_plan_to_queries[logical_plan].append(query_name)\n",
    "    full_plan_to_queries[full_plan].append(query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT_REL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group_summary(query_groups, only_interesting=True):\n",
    "    \"\"\"\n",
    "    In each query group it looks for cases, where hintset for one queries lead to boost \n",
    "    and for another one lead to degradation, and collects info about the most interesting ones.\n",
    "    \"\"\"\n",
    "    group_summaries = []\n",
    "    for query_group in query_groups:   \n",
    "        min_timeouts = 0\n",
    "        hs_to_show, def_times_to_show, cust_times_to_show, boosts_to_show = None, None, None, None\n",
    "        \n",
    "        for hs in HINTSETS:\n",
    "            def_times, cust_times, speedups, boosts = [], [], [], []\n",
    "            for q_n in sorted(query_group):\n",
    "                cust_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP))\n",
    "                def_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP))\n",
    "                \n",
    "                def_times.append(def_time)\n",
    "                cust_times.append(cust_time)\n",
    "                speedups.append(def_time - cust_time)\n",
    "\n",
    "                if cust_time >= TIMEOUT:\n",
    "                    boosts.append(-TIMEOUT_REL)\n",
    "                elif cust_time > def_time:\n",
    "                    boosts.append(-cust_time / def_time)\n",
    "                else:\n",
    "                    boosts.append(def_time / cust_time)\n",
    "\n",
    "            are_queries_small = max(def_times) < 1000\n",
    "            if only_interesting and are_queries_small:\n",
    "               continue\n",
    "            \n",
    "            n_timeouts = sum([boost == -TIMEOUT_REL for boost in boosts])\n",
    "            new_n_timeouts_record = (n_timeouts > min_timeouts)\n",
    "            n_min_timeouts = (n_timeouts == min_timeouts)\n",
    "            new_boost_record = (hs_to_show is None or max(boosts_to_show) <= max(boosts))\n",
    "            boost_is_large_enough = (max(boosts) > 1.01)\n",
    "\n",
    "            if (new_n_timeouts_record or (n_min_timeouts and new_boost_record)) and boost_is_large_enough:\n",
    "                min_timeouts = n_timeouts\n",
    "                hs_to_show = hs\n",
    "                def_times_to_show = def_times\n",
    "                cust_times_to_show = cust_times\n",
    "                boosts_to_show = boosts\n",
    "                speedups_to_show = speedups\n",
    "            \n",
    "        is_interesting_case_found = (hs_to_show is not None and len(query_group) > 1)\n",
    "        if is_interesting_case_found:\n",
    "            summary = (sorted(query_group), hs_to_show, speedups_to_show, def_times_to_show, cust_times_to_show)\n",
    "            group_summaries.append(summary)\n",
    "            \n",
    "    return group_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logical tree $\\rightarrow t^{ex}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_plan_summary = make_group_summary(query_groups=logical_plan_to_queries.values())\n",
    "logical_plan_summary = sorted(logical_plan_summary, key=lambda el: max(el[2]) - min(el[2]), reverse=True)\n",
    "\n",
    "data = []\n",
    "for (query_group, hs, speedups, def_times, cust_times) in logical_plan_summary:\n",
    "    boosts = []\n",
    "    for cust_time, def_time in zip(cust_times, def_times):\n",
    "        if cust_time >= TIMEOUT:\n",
    "            boosts.append(\"`NaN`\")\n",
    "        elif cust_time < def_time:\n",
    "            boosts.append(round(def_time / cust_time, 2))\n",
    "        else:\n",
    "            boosts.append(round(-cust_time / def_time, 2))\n",
    "\n",
    "    cust_times = [round(v/1000, 2) if v < TIMEOUT else \"`T/O`\" for v in cust_times]\n",
    "    \n",
    "    def_times = [round(v/1000, 2) for v in def_times]\n",
    "\n",
    "    data.append({\n",
    "        \"Query Group\": query_group,\n",
    "        \"# hintset\": hs,\n",
    "        \"Default Ex. Time (sec)\": def_times,\n",
    "        \"Custom Ex. Time (sec)\": cust_times,\n",
    "        \"Boosts\": boosts,\n",
    "    }\n",
    "    )\n",
    "pd.DataFrame(data).to_csv(f\"{ARTIFACTS_PATH}/logical_plans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full plan $\\rightarrow t^{ex}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_plan_summary = make_group_summary(query_groups=full_plan_to_queries.values())\n",
    "full_plan_summary = sorted(full_plan_summary, key=lambda el: max(el[2]) - min(el[2]), reverse=True)\n",
    "\n",
    "data = []\n",
    "for (query_group, hs, speedups, def_times, cust_times) in full_plan_summary:\n",
    "    boosts = []\n",
    "    for cust_time, def_time in zip(cust_times, def_times):\n",
    "        if cust_time >= TIMEOUT:\n",
    "            boosts.append(\"`NaN`\")\n",
    "        elif cust_time < def_time:\n",
    "            boosts.append(round(def_time / cust_time, 2))\n",
    "        else:\n",
    "            boosts.append(round(-cust_time / def_time, 2))\n",
    "\n",
    "    cust_times = [round(v/1000, 2) if v < TIMEOUT else \"`T/O`\" for v in cust_times]\n",
    "    \n",
    "    def_times = [round(v/1000, 2) for v in def_times]\n",
    "\n",
    "    data.append({\n",
    "        \"Query Group\": query_group,\n",
    "        \"# hintset\": hs,\n",
    "        \"Default Ex. Time (sec)\": def_times,\n",
    "        \"Custom Ex. Time (sec)\": cust_times,\n",
    "        \"Boosts\": boosts,\n",
    "    }\n",
    "    )\n",
    "pd.DataFrame(data).to_csv(f\"{ARTIFACTS_PATH}/full_plans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** It can be seen that this representation is not sufficient for accurate estimation of even the execution time of plans. As a consequence, we cannot talk about predicting hintsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is pair $\\langle plan_{from}, plan_{to} \\rangle$ enough to safely estimate the usefullness of hintset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the boosts collected during query exploration are actually an attribute of the **transition**\n",
    "\n",
    "$$\\tau: Plan_{default} \\rightarrow \\text{*hints applying*} \\rightarrow Plan_{custom}$$\n",
    "\n",
    "it would be logical to consider the resulting plan when making decisions. If suddenly we get some new plan when applying the hintset, our prediction is no longer reliable and it is better to avoid it.\n",
    "\n",
    "Note: we considere only hintsets that are usefull for at least 1 query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_and_query_map(def_plan_extractor, custom_plan_extractor, oracle):\n",
    "    \"\"\"For each query in oracle, by using given plan extractors, constructs 2 mappings:\n",
    "        a) transition -> `<custom_time, default_time>`, and\n",
    "        b) transition -> list of query names that have that transition with some hintset,\n",
    "    where transition is represented just as a string like \n",
    "    `f\"{def_plan_extractor(def_plan)} -> {custom_plan_extractor(custom_plan)}\"`.\n",
    "    \"\"\"\n",
    "    transitions = defaultdict(list)\n",
    "    transition_to_queries = defaultdict(list)\n",
    "\n",
    "    for q_n in oracle.get_query_names():\n",
    "        \n",
    "        def_plan = def_plan_extractor(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP)))\n",
    "        def_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP))\n",
    "        \n",
    "        for hs in HINTSETS:\n",
    "            custom_plan = custom_plan_extractor(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP)))\n",
    "            custom_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP))\n",
    "            transition_key = f\"{def_plan}->{custom_plan}\"\n",
    "            transitions[transition_key].append((custom_time, def_time))\n",
    "            transition_to_queries[transition_key].append(q_n)\n",
    "    \n",
    "    return transitions, transition_to_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transitions_summary(transitions, only_interesting=True):\n",
    "    \"\"\"for each of transition, that has sufficiently diverse performance\n",
    "    (e.g. T/O for one query and significant boost for another), returns\n",
    "    - max degradation\n",
    "    - speedups (in ms)\n",
    "    - boosts\n",
    "    - custom times (in ms)\n",
    "    - default times (in ms)\n",
    "    \"\"\"\n",
    "    transition_summaries = []\n",
    "    for transition, transition_info in transitions.items():\n",
    "        boosts, speedups, custom_times, def_times = [], [], [], []\n",
    "        \n",
    "        for info in transition_info:\n",
    "            cust_time, def_time = info\n",
    "            custom_times.append(cust_time)\n",
    "            def_times.append(def_time)\n",
    "\n",
    "            speedups.append(def_time - cust_time)\n",
    "\n",
    "            if cust_time >= TIMEOUT:\n",
    "                boosts.append(-TIMEOUT_REL)\n",
    "            elif cust_time > def_time:\n",
    "                boosts.append(-cust_time / def_time)\n",
    "            else:\n",
    "                boosts.append(def_time / cust_time)\n",
    "        \n",
    "        are_all_queries_small = (max(def_times) < 1000) and (max(custom_times) < 1000)\n",
    "        are_all_queries_boosted = (min(boosts) >= -1.0)\n",
    "        are_all_queries_deboosted = (max(boosts) <= 1.0)\n",
    "        \n",
    "        if only_interesting and (are_all_queries_small or are_all_queries_boosted or are_all_queries_deboosted):\n",
    "            continue\n",
    "        \n",
    "        is_there_big_deboost = -TIMEOUT_REL in boosts or max([c_t - d_t for c_t, d_t in zip(custom_times, def_times)]) > 500\n",
    "        if only_interesting and (not is_there_big_deboost):\n",
    "           continue\n",
    "        \n",
    "        summary = (min(boosts), speedups, custom_times, def_times, transition)\n",
    "        transition_summaries.append(summary)   \n",
    "        \n",
    "    return transition_summaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logical transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_transitions, logical_transition_to_queries = get_transitions_and_query_map(\n",
    "    oracle=oracle, \n",
    "    def_plan_extractor=get_logical_tree, \n",
    "    custom_plan_extractor=get_logical_tree\n",
    ")\n",
    "         \n",
    "transition_summary = make_transitions_summary(transitions=logical_transitions)\n",
    "transition_summary = sorted(transition_summary, key=lambda el: max(el[1]) - min(el[1]), reverse=True)\n",
    "\n",
    "data = []\n",
    "for max_degradation, speedups, cust_times, def_times, transition_key in transition_summary:\n",
    "    queries = logical_transition_to_queries[transition_key]\n",
    "    \n",
    "    q_to_def_times, q_to_cust_times = defaultdict(list), defaultdict(list)\n",
    "    for q_n, def_time, cust_time in sorted(zip(queries, def_times, cust_times)):\n",
    "        q_to_def_times[q_n].append(def_time)\n",
    "        q_to_cust_times[q_n].append(cust_time)\n",
    "\n",
    "    query_group, def_times, cust_times, boosts = [], [], [], []\n",
    "    for q_n in sorted(set(queries)):\n",
    "        query_group.append(q_n)\n",
    "\n",
    "        def_time = np.mean(q_to_def_times[q_n])\n",
    "        cust_time = TIMEOUT if max(q_to_cust_times[q_n]) >= TIMEOUT else np.mean(q_to_cust_times[q_n])\n",
    "\n",
    "        def_times.append(round(def_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            cust_times.append(\"`T\\\\O`\")\n",
    "        else:\n",
    "            cust_times.append(round(cust_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            boosts.append(\"`NaN`\")\n",
    "        elif cust_time > def_time:\n",
    "            boosts.append(round(-cust_time / def_time, 2))\n",
    "        else:\n",
    "            boosts.append(round(def_time / cust_time, 2))\n",
    "\n",
    "    data.append({\n",
    "        \"Query Group\": query_group,\n",
    "        \"Default Ex. Time (sec)\": def_times,\n",
    "        \"Custom Ex. Time (sec)\": cust_times,\n",
    "        \"Boosts\": boosts,\n",
    "    }\n",
    "    )\n",
    "pd.DataFrame(data).to_csv(f\"{ARTIFACTS_PATH}/logical_transitions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** Transition only between logic trees does not describe what is going on well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_transitions, full_transition_to_queries = get_transitions_and_query_map(\n",
    "    oracle=oracle, \n",
    "    def_plan_extractor=get_full_plan, \n",
    "    custom_plan_extractor=get_full_plan,\n",
    ")\n",
    "         \n",
    "transition_summary = make_transitions_summary(transitions=full_transitions, only_interesting=False)\n",
    "transition_summary = sorted(transition_summary, key=lambda el: max(el[1]) - min(el[1]), reverse=True)\n",
    "\n",
    "data = []\n",
    "for max_degradation, speedups, cust_times, def_times, transition_key in transition_summary:\n",
    "    queries = full_transition_to_queries[transition_key]\n",
    "    \n",
    "    q_to_def_times, q_to_cust_times = defaultdict(list), defaultdict(list)\n",
    "    for q_n, def_time, cust_time in sorted(zip(queries, def_times, cust_times)):\n",
    "        q_to_def_times[q_n].append(def_time)\n",
    "        q_to_cust_times[q_n].append(cust_time)\n",
    "\n",
    "    query_group, def_times, cust_times, boosts = [], [], [], []\n",
    "    for q_n in sorted(set(queries)):\n",
    "        query_group.append(q_n)\n",
    "\n",
    "        def_time = np.mean(q_to_def_times[q_n])\n",
    "        cust_time = TIMEOUT if max(q_to_cust_times[q_n]) >= TIMEOUT else np.mean(q_to_cust_times[q_n])\n",
    "\n",
    "        def_times.append(round(def_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            cust_times.append(\"`T\\\\O`\")\n",
    "        else:\n",
    "            cust_times.append(round(cust_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            boosts.append(\"`NaN`\")\n",
    "        elif cust_time > def_time:\n",
    "            boosts.append(round(-cust_time / def_time, 2))\n",
    "        else:\n",
    "            boosts.append(round(def_time / cust_time, 2))\n",
    "\n",
    "    data.append({\n",
    "        \"Query Group\": query_group,\n",
    "        \"Default Ex. Time (sec)\": def_times,\n",
    "        \"Custom Ex. Time (sec)\": cust_times,\n",
    "        \"Boosts\": boosts,\n",
    "    }\n",
    "    )\n",
    "pd.DataFrame(data).to_csv(f\"{ARTIFACTS_PATH}/full_transitions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** When using transitions between full plans, there is no longer a situation where we speed up one query and slow down the other one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy transition\n",
    "\n",
    "The only difference with full transitions is that we do not distinguish between full plans if the distance between them is not large enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(sels1, sels2):\n",
    "    \"\"\"calculates the maximum among the ratio values of all corresponding coordinates\"\"\"\n",
    "    try:\n",
    "        assert len(sels1) == len(sels2)\n",
    "        return max([max(sel1/sel2, sel2/sel1) for sel1, sel2 in zip(sels1, sels2)])\n",
    "    except Exception:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "sels1 = [(1, 12), (42, 666), (1, ), (1, 2), (1, 2, 3)]\n",
    "sels2 = [(2,  3), (42, 666), (2, ), (1, ) , None]\n",
    "expected_distances = [4, 1, 2, float(\"inf\"), float(\"inf\")]\n",
    "\n",
    "for sel1, sel2, expected_distance in zip(sels1, sels2, expected_distances):\n",
    "    assert get_distance(sel1, sel2) == expected_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fuzzy_transitions_and_query_map(oracle):\n",
    "    \"\"\"For each query in oracle constructs 2 mapping as in `get_transitions_and_query_map`.\n",
    "    The only difference is that instead of creating separated item for each transition\n",
    "    'default plan -> custom plan' it tries to squeezy items with same logical transition\n",
    "    'default logical plan -> custom logical plan' and close enough selectivities.\n",
    "\n",
    "    P.S. it has side effect -- squeezed transitions are written in 'SQUEEZED_TRANSITIONS' list.\n",
    "    \"\"\"\n",
    "    transitions = defaultdict(list)\n",
    "    transition_to_queries = defaultdict(list)\n",
    "\n",
    "    def_logical_trees_to_def_sels = defaultdict(list)\n",
    "    semi_transition_to_sels = defaultdict(list)\n",
    "\n",
    "    for q_n in oracle.get_query_names():\n",
    "        def_logical_tree = get_logical_tree(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP)))\n",
    "        def_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP))\n",
    "        def_sels = get_selectivities(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP)))\n",
    "\n",
    "        closest_def_sels = find_closest_sels(def_logical_trees_to_def_sels, def_logical_tree, def_sels)\n",
    "        can_reuse_def_sels = (get_distance(def_sels, closest_def_sels) < DISTANCE_THRESHOLD)\n",
    "        if can_reuse_def_sels:\n",
    "            def_sels = closest_def_sels\n",
    "        else:\n",
    "            def_logical_trees_to_def_sels[def_logical_tree].append(def_sels)\n",
    "\n",
    "        for hs in HINTSETS:\n",
    "            custom_logical_tree = get_logical_tree(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP)))\n",
    "            custom_sels = get_selectivities(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP)))\n",
    "            custom_time = oracle.get_execution_time(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP))\n",
    "            \n",
    "            #if custom_time >= TIMEOUT:\n",
    "            #    custom_time = TIMEOUT_REL * def_time\n",
    "\n",
    "            semi_transition_key = f\"{def_logical_tree}|{def_sels}->{custom_logical_tree}\"\n",
    "                \n",
    "            squeezed = False\n",
    "            closest_custom_sels = find_closest_sels(semi_transition_to_sels, semi_transition_key, custom_sels)\n",
    "\n",
    "            can_reuse_custom_sels = (get_distance(custom_sels, closest_custom_sels) < DISTANCE_THRESHOLD)\n",
    "            if can_reuse_custom_sels:\n",
    "                if (can_reuse_def_sels and closest_custom_sels is not None and closest_custom_sels != custom_sels):\n",
    "                    squeezed = True                \n",
    "                custom_sels = closest_custom_sels\n",
    "            else:\n",
    "                semi_transition_to_sels[semi_transition_key].append(custom_sels)\n",
    "\n",
    "            transition_key = f\"{def_logical_tree}|{def_sels}->{custom_logical_tree}|{custom_sels}\"\n",
    "\n",
    "            if squeezed:\n",
    "                real_def_sels = get_selectivities(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=DEFAULT_HINTSET, dop=DEFAULT_DOP)))\n",
    "                real_custom_sels = get_selectivities(oracle.get_explain_plan(OracleRequest(query_name=q_n, hintset=hs, dop=DEFAULT_DOP)))\n",
    "                assert closest_custom_sels != real_custom_sels\n",
    "                \n",
    "                SQUEEZED_TRANSITIONS.append((transition_key, (tuple(real_def_sels), tuple(real_custom_sels))))\n",
    "                SQUEEZED_TRANSITIONS.append((transition_key, (tuple(closest_def_sels), tuple(closest_custom_sels))))\n",
    "\n",
    "            transitions[transition_key].append((custom_time, def_time))\n",
    "            transition_to_queries[transition_key].append(q_n)\n",
    "\n",
    "    return transitions, transition_to_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_sels(logical_trees_to_sels, target_logical_tree, target_sels):\n",
    "    min_distance = float(\"inf\")\n",
    "    argmin_sels = None\n",
    "\n",
    "    for sels in logical_trees_to_sels[target_logical_tree]:\n",
    "        distance = get_distance(sels, target_sels)\n",
    "        if distance < min_distance:\n",
    "            min_distance, argmin_sels = distance, sels\n",
    "       \n",
    "    return argmin_sels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note,** the value of `DISTANCE_THRESHOLD` parameter is super important -  we can achieve both full and logical transitions by changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_THRESHOLD = 1.5\n",
    "SQUEEZED_TRANSITIONS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fuzzy():\n",
    "    global DISTANCE_THRESHOLD\n",
    "    global SQUEEZED_TRANSITIONS\n",
    "    tmp1, tmp2 = DISTANCE_THRESHOLD, SQUEEZED_TRANSITIONS\n",
    "    SQUEEZED_TRANSITIONS = []\n",
    "    \n",
    "    DISTANCE_THRESHOLD = float(\"inf\")\n",
    "    logical_transitions, logical_transition_to_queries = get_transitions_and_query_map(\n",
    "        oracle=oracle, \n",
    "        def_plan_extractor=get_logical_tree, \n",
    "        custom_plan_extractor=get_logical_tree\n",
    "    )\n",
    "    fuzzy_transitions, fuzzy_transition_to_queries = get_fuzzy_transitions_and_query_map(oracle=oracle)\n",
    "    assert len(fuzzy_transition_to_queries) == len(logical_transition_to_queries)\n",
    "\n",
    "    DISTANCE_THRESHOLD = 1.0 + 10 ** (-42)\n",
    "    full_transitions, full_transition_to_queries = get_transitions_and_query_map(\n",
    "        oracle=oracle, \n",
    "        def_plan_extractor=get_full_plan, \n",
    "        custom_plan_extractor=get_full_plan\n",
    "    )\n",
    "    fuzzy_transitions, fuzzy_transition_to_queries = get_fuzzy_transitions_and_query_map(oracle=oracle)    \n",
    "    assert len(fuzzy_transition_to_queries) == len(full_transition_to_queries)\n",
    "\n",
    "    DISTANCE_THRESHOLD = tmp1\n",
    "    SQUEEZED_TRANSITIONS = tmp2\n",
    "    \n",
    "test_fuzzy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUEEZED_TRANSITIONS = []\n",
    "fuzzy_transitions, fuzzy_transition_to_queries = get_fuzzy_transitions_and_query_map(\n",
    "    oracle=oracle\n",
    ")\n",
    "\n",
    "# lets analyze only squeezed\n",
    "squeezed_transition_to_real_sels_pairs = defaultdict(set)\n",
    "for (transition, sels) in SQUEEZED_TRANSITIONS:\n",
    "    squeezed_transition_to_real_sels_pairs[transition].add(sels)\n",
    "\n",
    "transition_summary = make_transitions_summary(transitions=fuzzy_transitions, only_interesting=False)\n",
    "transition_summary = sorted(transition_summary, key=lambda el: max(el[1]) - min(el[1]), reverse=True)\n",
    "\n",
    "data = []\n",
    "for max_degradation, speedups, cust_times, def_times, transition_key in transition_summary:\n",
    "\n",
    "    if transition_key not in squeezed_transition_to_real_sels_pairs:\n",
    "        continue\n",
    "    \n",
    "    if all([c_t >= TIMEOUT for c_t in cust_times]):\n",
    "        continue\n",
    "\n",
    "    queries = fuzzy_transition_to_queries[transition_key]\n",
    "    \n",
    "    q_to_def_times, q_to_cust_times = defaultdict(list), defaultdict(list)\n",
    "    for q_n, def_time, cust_time in sorted(zip(queries, def_times, cust_times)):\n",
    "        q_to_def_times[q_n].append(def_time)\n",
    "        q_to_cust_times[q_n].append(cust_time)\n",
    "\n",
    "    query_group, def_times, cust_times, boosts = [], [], [], []\n",
    "    for q_n in sorted(set(queries)):\n",
    "        query_group.append(q_n)\n",
    "\n",
    "        def_time = np.mean(q_to_def_times[q_n])\n",
    "        cust_time = TIMEOUT if max(q_to_cust_times[q_n]) >= TIMEOUT else np.mean(q_to_cust_times[q_n])\n",
    "\n",
    "        def_times.append(round(def_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            cust_times.append(\"`T\\\\O`\")\n",
    "        else:\n",
    "            cust_times.append(round(cust_time / 1000, 2))\n",
    "\n",
    "        if cust_time >= TIMEOUT:\n",
    "            boosts.append(\"`NaN`\")\n",
    "        elif cust_time > def_time:\n",
    "            boosts.append(round(-cust_time / def_time, 2))\n",
    "        else:\n",
    "            boosts.append(round(def_time / cust_time, 2))\n",
    "\n",
    "    data.append({\n",
    "        \"Query Group\": query_group,\n",
    "        \"Default Ex. Time (sec)\": def_times,\n",
    "        \"Custom Ex. Time (sec)\": cust_times,\n",
    "        \"Boosts\": boosts,\n",
    "    }\n",
    "    )\n",
    "    \n",
    "pd.DataFrame(data).to_csv(f\"{ARTIFACTS_PATH}/fuzzy_transitions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** Even fuzzy transitions are a good enough way to describe queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
