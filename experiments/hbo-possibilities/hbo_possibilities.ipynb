{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "BTCNN_PATH = os.path.join(ROOT_PATH, \"btcnn\")\n",
    "HBO_BENCH_PATH = os.path.join(ROOT_PATH, \"hbo_bench\")\n",
    "\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "sys.path.insert(0, BTCNN_PATH)\n",
    "sys.path.insert(0, HBO_BENCH_PATH)\n",
    "\n",
    "EXPERIMENT_PATH = os.getcwd()\n",
    "ARTIFACTS_PATH = os.path.join(EXPERIMENT_PATH, \"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load, dumps, dump\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from hbo_bench.oracle import Oracle, OracleRequest, TIMEOUT\n",
    "from hbo_bench.data_config import HINTSETS, DOPS, HINTS, DEFAULT_HINTSET, DEFAULT_DOP\n",
    "from hbo_bench.utils import get_logical_tree, get_full_plan\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_oracles = {\n",
    "    \"JOB\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/JOB\"),\n",
    "    \"TPCH\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/tpch_10gb\"),\n",
    "    \"SQ\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/sample_queries\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e2e_time(oracle, q_n, hs, dop):\n",
    "    request = OracleRequest(query_name=q_n, hintset=hs, dop=dop)\n",
    "    return (oracle.get_planning_time(request) + oracle.get_execution_time(request)) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(\n",
    "    times, \n",
    "    labels, \n",
    "    names, \n",
    "    xlabel='Query',\n",
    "    ylabel='Execution Time (s)',\n",
    "    title=\"Execution Time Comparison\",\n",
    "    figsize=(12, 6),\n",
    "    bar_width=0.25,\n",
    "    label_fontsize=15, \n",
    "    title_fontsize=18, \n",
    "    tick_label_fontsize=15, \n",
    "    legend_fontsize=15, \n",
    "    bar_label_fontsize=13,\n",
    "    save_name=None\n",
    "):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_palette(\"deep\")\n",
    "    \n",
    "    x = np.arange(len(names))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        ax.bar(x + i * bar_width, times[:, i], bar_width, label=labels[i])\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(x[i] + j * bar_width, times[i, j], f'{times[i, j]:.1f}s', ha='center', va='bottom', fontsize=bar_label_fontsize, fontweight='bold')\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=label_fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=label_fontsize)\n",
    "    ax.set_title(title, fontsize=title_fontsize)\n",
    "    ax.set_xticks(x + bar_width)\n",
    "    ax.set_xticklabels(names, fontsize=tick_label_fontsize)\n",
    "    ax.legend(fontsize=legend_fontsize, loc='best')\n",
    "    ax.grid(alpha=0.3, color='gray')\n",
    "    \n",
    "    if save_name:\n",
    "        plt.savefig(f\"{ARTIFACTS_PATH}/{save_name}\", format='svg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "For advising good hints we must take into accout planner's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_oracle = cached_oracles[\"JOB\"]\n",
    "OFF_NL_HINT = 64\n",
    "OFF_INL_HINT = 64 | 8 | 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_names = [\"16b\", \"24b\"]\n",
    "times = np.array([\n",
    "    [get_e2e_time(job_oracle, q_n, hs, DEFAULT_DOP) for hs in [DEFAULT_HINTSET, OFF_NL_HINT, OFF_INL_HINT]]\n",
    "    for q_n in query_names\n",
    "])\n",
    "\n",
    "labels = ['Def', 'NL', 'NL, BMS, IS']\n",
    "plot_bars(times, labels, query_names, title=\"\", save_name=\"example_16b_24b.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** \\\n",
    "Comparing the behaviour of these same queries with the same hints on `PostgreSQL` (as in `Bao`'s article), we can see that it is *fundamentally different*. This is because `openGauss` has a slightly different scheduler, and in case of `16b` it ignores switching off `NestedLoop` (actually `Nested Index Loop Join` is switched off only by a combination of several hints at once). Moreover, we can immediately realise - that there are **no universally good hints** - they can both significantly speed up queries (`16b`) and repeatedly slow down others (`24b`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "There're no universally good hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_names = [\"25a\", \"6b\"]\n",
    "times = np.array([\n",
    "    [get_e2e_time(job_oracle, q_n, hs, dop) for (hs, dop) in [(DEFAULT_HINTSET, DEFAULT_DOP), (OFF_INL_HINT, DEFAULT_DOP), (OFF_INL_HINT, 16)]]\n",
    "    for q_n in query_names\n",
    "])\n",
    "\n",
    "labels = ['Def.', 'NL, BMS, IS', 'NL, BMS, IS, DOP']\n",
    "plot_bars(times, labels, query_names, title=\"\", save_name=\"example_25a6b.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what happens with query `25a`, we can analyse the plans:\n",
    "\n",
    "```python\n",
    "dop = 16\n",
    "with open(f\"{HBO_BENCH_PATH}/data/raw/dop{dop}/JOB.json\", \"r\") as f:\n",
    "    job_data = load(f)\n",
    "query_data = job_data[\"25a.sql\"]\n",
    "explain_plan = query_data[\"hs_to_explain_plan\"][str(OFF_INL_HINT)]\n",
    "query_data[\"explain_plan_to_explain_analyze_plan\"][dumps(explain_plan)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Plan:**\n",
    "\n",
    "```python\n",
    "'Node Type': 'Nested Loop',\n",
    "'Plan Rows': 5,\n",
    "'Actual Total Time': 3157.857,\n",
    "'Actual Rows': 12438,\n",
    "'Actual Loops': 1,\n",
    "'Plans': [\n",
    "    {\n",
    "        'Node Type': 'Seq Scan',\n",
    "        'Plan Rows': 1,\n",
    "        'Actual Startup Time': 0.057,\n",
    "        'Actual Total Time': 0.087,\n",
    "        'Actual Rows': 1,\n",
    "        'Actual Loops': 1,\n",
    "    },\n",
    "    {\n",
    "        'Node Type': 'Nested Loop',\n",
    "        'Plan Rows': 166,\n",
    "        'Actual Total Time': 3150.975,\n",
    "        'Actual Rows': 13309,\n",
    "        'Actual Loops': 1,\n",
    "        'Plans': [\n",
    "            {\n",
    "                'Node Type': 'Nested Loop',\n",
    "                'Plan Rows': 165,\n",
    "                'Actual Total Time': 211.298,\n",
    "                'Actual Rows': 62096, # 165 << 62096 - huge cardinality underestimation\n",
    "                'Actual Loops': 1,\n",
    "                'Plans': [\n",
    "                    {\n",
    "                        'Node Type': 'Seq Scan',\n",
    "                        'Plan Rows': 5,\n",
    "                        'Actual Total Time': 60.023,\n",
    "                        'Actual Rows': 5,\n",
    "                        'Actual Loops': 1,\n",
    "                    },\n",
    "                    {\n",
    "                        'Node Type': 'Bitmap Heap Scan',\n",
    "                        'Plan Rows': 33,\n",
    "                        'Actual Total Time': 136.146,\n",
    "                        'Actual Rows': 62096,\n",
    "                        'Actual Loops': 5,\n",
    "                        'Plans': [\n",
    "                            {\n",
    "                                'Node Type': 'Bitmap Index Scan',\n",
    "                                'Plan Rows': 33,\n",
    "                                'Actual Total Time': 12.456,\n",
    "                                'Actual Rows': 62096, # the source of underestimation\n",
    "                                'Actual Loops': 5,\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'Node Type': 'Index Scan',\n",
    "                'Plan Rows': 1,\n",
    "                'Actual Total Time': 2901.719,  # that is ~50% of execution time\n",
    "                'Actual Rows': 13309,\n",
    "                'Actual Loops': 62096,  # planner expected only 165 look-ups here\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan with disabled Nested Loop:**\n",
    "\n",
    "```python\n",
    "...\n",
    "'Node Type': 'Streaming(type: BROADCAST dop: 64/1)',\n",
    "'Plan Rows': 16256,  # 16256 << 9774080 - huge cardinality underestimation\n",
    "'Actual Min Total Time': 11134.643,\n",
    "'Actual Max Total Time': 11327.461,\n",
    "'Actual Total Rows': 9774080,\n",
    "'Plans': [\n",
    "  {\n",
    "    'Node Type': 'Hash Join',\n",
    "    'Plan Rows': 254,\n",
    "    'Actual Min Total Time': 4374.092,\n",
    "    'Actual Max Total Time': 4374.092,\n",
    "    'Actual Total Rows': 152720,\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion.** \\\n",
    "The cause of errors is a huge underestimation of cardinality, which led to calling `60K` index lookups. In the situation when the nested loop is disabled, the planner chooses `HashJoin`, but at some point it parallelises the join of a huge relation (`10M`+) on 64 threads, because of which it gets a huge overhead. With lower degree of parallelism this does not happen (different plan is built)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOP\n",
    "\n",
    "Control of the degree of parallelism (`dop`) parameter is also useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOP helps accelerate the workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_time(oracle, query_name, hintsets, dops):\n",
    "    return min(get_e2e_time(oracle, query_name, hs, dop) for hs in hintsets for dop in dops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worst_time(oracle, query_name, hintsets, dops):\n",
    "    return max(get_e2e_time(oracle, query_name, hs, dop) for hs in hintsets for dop in dops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "labels = [\"Default\", \"DOP\", \"OPs\", \"OPs & DOP\"]\n",
    "\n",
    "for bench_name, oracle in cached_oracles.items():\n",
    "    ops_best_time = sum(get_best_time(oracle, q_n, HINTSETS, [DEFAULT_DOP]) for q_n in oracle.get_query_names())\n",
    "    dop_best_time = sum(get_best_time(oracle, q_n, [DEFAULT_HINTSET], DOPS) for q_n in oracle.get_query_names())\n",
    "    ops_and_dop_best_time = sum(get_best_time(oracle, q_n, HINTSETS, DOPS) for q_n in oracle.get_query_names())\n",
    "    def_time = sum(get_best_time(oracle, q_n, [DEFAULT_HINTSET], [DEFAULT_DOP]) for q_n in oracle.get_query_names())\n",
    "    times.append([def_time, dop_best_time, ops_best_time, ops_and_dop_best_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(\n",
    "    np.array(times), \n",
    "    labels, \n",
    "    cached_oracles.keys(),\n",
    "    figsize=(12, 7),\n",
    "    bar_width=0.23,\n",
    "    xlabel=\"Benchmark\",\n",
    "    ylabel=\"Total Execution Time (s)\",\n",
    "    save_name=\"example_search_space.svg\",\n",
    "    title=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the boost from applying hints depends on the benchmark. For example, on `TPCH` the gain is much less than on `JOB`, and even more so on `SQ`. The reason is that we only correct the planner's errors - if it is not wrong, we have nothing to optimise. At the same time, the degree of parallelism itself is a rather effective parameter for optimisation and it also allows us to accelerate workload after applying hints on operators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOP expands the search space and raises the problem of effective exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exploration_time(oracle, query_name, hintsets, dops):\n",
    "    return sum(\n",
    "        min(get_e2e_time(oracle, query_name, hs, dop), get_e2e_time(oracle, query_name, DEFAULT_HINTSET, DEFAULT_DOP))    \n",
    "        for hs in hintsets for dop in dops\n",
    "    )\n",
    "    \n",
    "def get_planning_time(oracle, query_name, hintsets, dops):\n",
    "    return sum(\n",
    "        oracle.get_planning_time(OracleRequest(query_name=query_name, hintset=hs, dop=dop)) / 1000\n",
    "        for hs in hintsets for dop in dops\n",
    "    )\n",
    "\n",
    "def get_explain_plan(oracle, query_name, hintset, dop):\n",
    "    return oracle.get_explain_plan(OracleRequest(query_name=query_name, hintset=hintset, dop=dop))\n",
    "\n",
    "def get_n_logical_trees(oracle, query_name, hintsets, dops):\n",
    "    return len(set(get_logical_tree(get_explain_plan(oracle, query_name, hs, dop)) for hs in hintsets for dop in dops))\n",
    "\n",
    "def get_n_full_plans(oracle, query_name, hintsets, dops):\n",
    "    return len(set(get_full_plan(get_explain_plan(oracle, query_name, hs, dop)) for hs in hintsets for dop in dops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(oracle, hintsets, dops):\n",
    "    stats = {\n",
    "        \"exploration_time\": 0,\n",
    "        \"planning_time\": 0,\n",
    "        \"n_logical_trees\": 0,\n",
    "        \"n_full_plans\": 0,\n",
    "        \"size\": 0\n",
    "    }\n",
    "\n",
    "    for q_n in oracle.get_query_names():\n",
    "        stats[\"exploration_time\"] += get_exploration_time(oracle, q_n, hintsets, dops)\n",
    "        stats[\"planning_time\"] += get_planning_time(oracle, q_n, hintsets, dops)\n",
    "        stats[\"n_logical_trees\"] += get_n_logical_trees(oracle, q_n, hintsets, dops)\n",
    "        stats[\"n_full_plans\"] += get_n_full_plans(oracle, q_n, hintsets, dops)\n",
    "        stats[\"size\"] += len(hintsets) * len(dops)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_stats_table(cached_oracles, labels, params):\n",
    "    data = []\n",
    "    for label, (hintsets, dops) in zip(labels, params):\n",
    "        for bench_name, oracle in cached_oracles.items():\n",
    "            stats = calculate_stats(oracle, hintsets, dops)\n",
    "            data.append([\n",
    "                bench_name, label, \n",
    "                int(stats[\"exploration_time\"]),\n",
    "                int(stats[\"planning_time\"]), \n",
    "                int(stats[\"n_logical_trees\"]), \n",
    "                int(stats[\"n_full_plans\"]), \n",
    "                int(stats[\"size\"])\n",
    "            ])\n",
    "\n",
    "    columns = [\"Benchmark\", \"Search Space\", \"E2E Time (sec)\", \"Planning Time (sec)\", \n",
    "               \"# Unique Trees\", \"# Unique Plans\", \"# Plans\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    benchmark_order = [\"TPCH\", \"JOB\", \"SQ\"]\n",
    "    df['Benchmark'] = pd.Categorical(df['Benchmark'], categories=benchmark_order, ordered=True)\n",
    "    df = df.sort_values('Benchmark').reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = [\"DOP\", \"OPs\", \"OPs & DOP\"]\n",
    "params = [([DEFAULT_HINTSET], DOPS), (HINTSETS, [DEFAULT_DOP]), (HINTSETS, DOPS)]\n",
    "\n",
    "df = get_stats_table(cached_oracles, labels, params)\n",
    "df = df.pivot_table(index=\"Benchmark\", columns=\"Search Space\", values=[\"E2E Time (sec)\", \"Planning Time (sec)\", \"# Unique Trees\", \"# Unique Plans\", \"# Plans\"], observed=False)\n",
    "\n",
    "df[\"E2E Time (sec)\"] = df[\"E2E Time (sec)\"].astype(int)\n",
    "df[\"Planning Time (sec)\"] = df[\"Planning Time (sec)\"].astype(int)\n",
    "df[\"# Unique Trees\"] = df[\"# Unique Trees\"].astype(int)\n",
    "df[\"# Unique Plans\"] = df[\"# Unique Plans\"].astype(int)\n",
    "df[\"# Plans\"] = df[\"# Plans\"].astype(int)\n",
    "\n",
    "pivot_df = df.reorder_levels([1, 0], axis=1).sort_index(axis=1)\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "pivot_df.to_csv(f\"{ARTIFACTS_PATH}/search_space_statistics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degradations\n",
    "\n",
    "Hint can slow down the query, so it is necessary to build a **reliable** model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN = \"#55a868\"\n",
    "ORANGE = \"#dd8452\"\n",
    "BLUE = \"#4c72b0\"\n",
    "RED = \"#c44e52\"\n",
    "TIMEOUT_REL = -1\n",
    "TIMEOUT_VAL = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_query_number(query_name):\n",
    "    import re\n",
    "    return int(re.search(r\"-?\\d+\\.?\\d*\", query_name).group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_query_bars(\n",
    "    names, \n",
    "    boosts, \n",
    "    degradations, \n",
    "    title=\"\", \n",
    "    path_to_save=None,\n",
    "    bar_width=0.7,\n",
    "    label_fontsize=15, \n",
    "    title_fontsize=18, \n",
    "    tick_label_fontsize=10, \n",
    "    legend_fontsize=15,\n",
    "    figsize=(12, 6),\n",
    "    grid_alpha=0.3,\n",
    "    grid_color='gray'\n",
    "):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_palette(\"deep\")\n",
    "\n",
    "    index = np.arange(len(names))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    timeout_index = [i for i, degr in enumerate(degradations) if degr == TIMEOUT_REL]\n",
    "    degradation_index = [i for i, degr in enumerate(degradations) if degr != TIMEOUT_REL]\n",
    "    \n",
    "    degradation_vals = [degradations[i] for i in degradation_index]\n",
    "    \n",
    "    boost_bars = ax.bar(index, boosts, bar_width, label='Max Boost', color=GREEN)\n",
    "    \n",
    "    if timeout_index:\n",
    "        timeout_vals = [TIMEOUT_VAL for _ in timeout_index]\n",
    "        timeout_bars = ax.bar(timeout_index, timeout_vals, bar_width, label='T/O', color=RED)\n",
    "    \n",
    "    if degradation_index:\n",
    "        degrade_bars = ax.bar(degradation_index, degradation_vals, bar_width, label='Max Degradation', color=ORANGE)\n",
    "    \n",
    "    left_edge = index[0] - bar_width / 2\n",
    "    right_edge = index[-1] + bar_width / 2\n",
    "    ax.plot([left_edge, right_edge], [0.0, 0.0], color='white', linewidth=0.1, linestyle='-')\n",
    "\n",
    "    ax.set_yscale(\"symlog\")\n",
    "    ax.set_xlabel('Query', fontsize=label_fontsize)\n",
    "    ax.set_ylabel('Relative Boost (log scale)', fontsize=label_fontsize)\n",
    "    ax.set_title(title, fontsize=title_fontsize)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(names, rotation=90, fontsize=tick_label_fontsize, fontweight='bold')\n",
    "    ax.legend(fontsize=legend_fontsize, loc=\"upper right\")\n",
    "    ax.grid(alpha=0.3, color='gray')\n",
    "    \n",
    "    if path_to_save:\n",
    "        plt.savefig(path_to_save, dpi=300, format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bench_name, oracle in cached_oracles.items():\n",
    "    names, boosts, degradations = [], [], []\n",
    "    for q_n in sorted(oracle.get_query_names(), key=lambda el: (_extract_query_number(el), el)):\n",
    "        \n",
    "        best_time = get_best_time(oracle, q_n, HINTSETS, DOPS) \n",
    "        worst_time = get_worst_time(oracle, q_n, HINTSETS, DOPS) \n",
    "        def_time = get_best_time(oracle, q_n, [DEFAULT_HINTSET], [DEFAULT_DOP]) \n",
    "\n",
    "        names.append(q_n)\n",
    "        boosts.append(def_time / best_time - 1)\n",
    "        if worst_time >= TIMEOUT/1000:\n",
    "            degradations.append(TIMEOUT_REL)\n",
    "        else:\n",
    "            degradations.append(-((worst_time / def_time) - 1))\n",
    "\n",
    "    plot_per_query_bars(\n",
    "        names=names,\n",
    "        boosts=boosts,\n",
    "        degradations=degradations,\n",
    "        figsize=(20, 10),\n",
    "        path_to_save=f\"{ARTIFACTS_PATH}/{bench_name}_extreme_cases.svg\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
