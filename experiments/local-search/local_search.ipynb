{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "BTCNN_PATH = os.path.join(ROOT_PATH, \"btcnn/src/btcnn\")\n",
    "HBO_BENCH_PATH = os.path.join(ROOT_PATH, \"hbo_bench/src/hbo_bench\")\n",
    "\n",
    "sys.path.insert(0, ROOT_PATH)\n",
    "\n",
    "EXPERIMENT_PATH = os.getcwd()\n",
    "ARTIFACTS_PATH = os.path.join(EXPERIMENT_PATH, \"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from json import load, dumps, dump\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hbo_bench.oracle import Oracle, OracleRequest, TIMEOUT\n",
    "from hbo_bench.data_config import HINTSETS, DOPS, HINTS, DEFAULT_HINTSET, DEFAULT_DOP\n",
    "from hbo_bench.utils import get_logical_tree, get_full_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_oracles = {\n",
    "    \"JOB\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/JOB\"),\n",
    "    \"TPCH\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/tpch_10gb\"),\n",
    "    \"SQ\": Oracle(f\"{HBO_BENCH_PATH}/data/processed/sample_queries\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the vastness of the search space, even with boolean hints ($2^{\\# \\text{hintsets}}$), and our desire to manage the degree of parallelism (`DOP` value), we are compelled to find ways to reduce the search space. \n",
    "\n",
    "Initially, a **greedy algorithm** was considered, which sequentially disables hintsets. However, it was observed in practice that disabling a single operation is sometimes insufficient to achieve the desired result. This led to the decision to implement additional actions such as \"disable `BMS` & `IS` & `NL`,\" and parameterisze action space itself for allowing balancing between exploration speed and performance. It made the search algorithm looks like a local search algorithm.\n",
    "\n",
    "Since it is not predetermined which actions are most promising, we **parameterize** the general algorithm scheme and **empirically determine the most suitable combinations of actions for each scenario**. It is evident that the more actions we add, the more extensively we will explore, thereby potentially finding better solutions, but at the cost of increased search expenses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that a) often very good solutions exist near the initial state, b) the number of unique plans is relatively small, and c) the quality of `SearchingState` is determined solely by the plan, we propose the following techniques to reduce training time:\n",
    "- limit the number of iterations in local search.\n",
    "- pre-plan neighbors and avoid executing the same plans repeatedly.\n",
    "- use timeouts when exploring neighbors (there is no point in waiting for a request to complete if it will take longer than the best known solution).\n",
    "- implement aggressive timeout\n",
    "- use only subset of moves (i.e., consider only a specific part of the neighborhood, for example, limit to just turning off `INL` or decreasing `DOP`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFF_INL_HINT = 64 | 8 | 2\n",
    "N_SCANS = 4\n",
    "N_JOINS = 3\n",
    "assert N_SCANS + N_JOINS == len(HINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_explorer import QueryExplorer, SearchingSettings, SearchingState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# we added 2 additional parameters to show that we need them\n",
    "ExtendedSearchingSettings = namedtuple(\n",
    "    \"ExtendedSearchingSettings\",\n",
    "    SearchingSettings._fields + (\"avoid_duplicates\", \"prioritize_neighbors\"),\n",
    "    defaults=tuple(SearchingSettings._field_defaults.values()) + (False, False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_pool = []\n",
    "for disable_scans in [False, True]:\n",
    "    for disable_joins in [False, True]:\n",
    "        for decrease_dop in [False, True]:\n",
    "            for disable_inl in [False, True]:\n",
    "                for relative_boost_threshold in [1.0, 1.1, 1.2, 1.5, 2.0]:   \n",
    "                    for max_iter in [1, 2, float(\"inf\")]:\n",
    "                        for avoid_duplicates in [False, True]:\n",
    "                            for use_joined_search in [False, True]:\n",
    "                                for prioritize_neighbors in [False, True]:\n",
    "                                    settings = ExtendedSearchingSettings(\n",
    "                                        disable_scans=disable_scans,\n",
    "                                        disable_joins=disable_joins,\n",
    "                                        decrease_dop=decrease_dop, \n",
    "                                        disable_inl=disable_inl, \n",
    "                                        relative_boost_threshold=relative_boost_threshold,\n",
    "                                        max_iter=max_iter,\n",
    "                                        avoid_duplicates=avoid_duplicates,\n",
    "                                        use_joined_search=use_joined_search,\n",
    "                                        prioritize_neighbors=prioritize_neighbors,\n",
    "                                    )\n",
    "                                    settings_pool.append(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_plan(plan: \"ExplainPlan\") -> \"str\":\n",
    "    res = []\n",
    "    def recurse(node: \"ExplainNode\") -> \"None\":\n",
    "        res.append(\n",
    "            f\"{node.node_type} (Rel={node.relation_name}|Index={node.index_name}|Cards={node.estimated_cardinality})\"\n",
    "        )\n",
    "        res.append(\"[\")\n",
    "        for child in node.plans:\n",
    "            recurse(child)\n",
    "        res.append(\"]\")\n",
    "    recurse(node=plan.plan)\n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialQueryExplorer(QueryExplorer):\n",
    "    def run(self) -> \"SearchingState\":\n",
    "\n",
    "        self.sequential_planning_time = 0\n",
    "        self.sequential_e2e_time = 0\n",
    "        self.seen_plans = set()\n",
    "\n",
    "        def_state = SearchingState(self.settings.default_hintset, self.settings.default_dop)\n",
    "        prev_state, record_state, record_time = None, def_state, float(\"inf\")\n",
    "        it = 0\n",
    "        while it < self.settings.max_iter and prev_state != record_state:\n",
    "            timeout, prev_state = record_time / self.settings.relative_boost_threshold, record_state\n",
    "            neighbors = list(filter(lambda st: st not in self.tried_states, self.get_neighbors(state=record_state)))\n",
    "            if not neighbors:\n",
    "                break  # pragma: no cover\n",
    "            best_ngb_time, best_ngb = self.explore_sequentially(neighbors, timeout)\n",
    "            if best_ngb_time < timeout:\n",
    "                record_state, record_time = best_ngb, best_ngb_time\n",
    "            it += 1\n",
    "        assert self.get_e2e_time(record_state) <= self.get_e2e_time(def_state), (self.query_name, record_state)\n",
    "        return record_state\n",
    "\n",
    "    def explore_sequentially(self, neighbors: \"List[SearchingState]\", timeout: \"Time\") -> \"Tuple[Time, SearchingState]\":\n",
    "\n",
    "        def_state = SearchingState(self.settings.default_hintset, self.settings.default_dop)\n",
    "        record_time, record_state = float(\"inf\"), neighbors[0]\n",
    "\n",
    "        if self.settings.prioritize_neighbors:\n",
    "            neighbors = sorted(neighbors, key=lambda st: self.get_e2e_time(st))\n",
    "\n",
    "        for ngb_state in neighbors:\n",
    "            self.tried_states.add(ngb_state)\n",
    "\n",
    "            saved_timeout, timeout = timeout, TIMEOUT if ngb_state == def_state else timeout\n",
    "\n",
    "            ngb_planning_time = min(self.get_planning_time(ngb_state), timeout)\n",
    "            self.sequential_planning_time += ngb_planning_time\n",
    "            if ngb_planning_time == timeout:\n",
    "                self.sequential_e2e_time += ngb_planning_time\n",
    "                continue\n",
    "            ngb_plan = self._get_explain_plan(state=ngb_state)\n",
    "            \n",
    "            ngb_e2e_time = self.get_e2e_time(ngb_state)\n",
    "            if self.settings.avoid_duplicates and get_full_plan(ngb_plan) in self.seen_plans:\n",
    "                self.sequential_e2e_time += ngb_planning_time                                \n",
    "            else:\n",
    "                self.sequential_e2e_time += min(ngb_e2e_time, timeout)\n",
    "            \n",
    "            self.seen_plans.add(get_full_plan(ngb_plan))\n",
    "              \n",
    "            timeout = min(saved_timeout, ngb_e2e_time)\n",
    "\n",
    "            if ngb_e2e_time < record_time:\n",
    "                record_state, record_time = ngb_state, ngb_e2e_time\n",
    "                if self.settings.prioritize_neighbors:\n",
    "                    break             \n",
    "\n",
    "        return record_time, record_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Collecting performance for each settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_times = defaultdict(dict)\n",
    "learning_times = defaultdict(dict)\n",
    "\n",
    "for settings in tqdm(settings_pool):\n",
    "    for bench_name, oracle in cached_oracles.items():\n",
    "        e2e_time, learning_time = 0, 0\n",
    "        for query_name in oracle.get_query_names():\n",
    "            explorer = SequentialQueryExplorer(query_name=query_name, oracle=oracle, settings=settings)\n",
    "            hintset, dop = explorer.run()\n",
    "            learning_time += explorer.sequential_e2e_time\n",
    "            request = OracleRequest(query_name=query_name, hintset=hintset, dop=dop)\n",
    "            e2e_time += explorer.get_e2e_time(SearchingState(hintset, dop))\n",
    "        e2e_times[bench_name][settings] = round(e2e_time, 3)\n",
    "        learning_times[bench_name][settings] = round(learning_time, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Collecting info for baseline and ideal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_e2e_times = {}\n",
    "def_times = {}\n",
    "\n",
    "all_states = [SearchingState(hintset, dop) for dop in DOPS for hintset in HINTSETS] # here\n",
    "\n",
    "for bench_name, oracle in cached_oracles.items():\n",
    "    best_e2e_time, def_time = 0, 0\n",
    "    for query_name in oracle.get_query_names():\n",
    "        explorer = SequentialQueryExplorer(query_name=query_name, oracle=oracle, settings=settings)\n",
    "        best_hintset, best_dop = min(all_states, key=lambda st: explorer.get_e2e_time(st))\n",
    "        best_e2e_time += explorer.get_e2e_time(SearchingState(best_hintset, best_dop))\n",
    "        def_time +=  explorer.get_e2e_time(SearchingState(DEFAULT_HINTSET, DEFAULT_DOP))\n",
    "\n",
    "    best_e2e_times[bench_name] = round(best_e2e_time, 3)\n",
    "    def_times[bench_name] = round(def_time, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Measuring the performance for default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_settings(settings, bench_name):\n",
    "    e2e_time = e2e_times[bench_name][settings]\n",
    "    boost = def_times[bench_name] - e2e_times[bench_name][settings]\n",
    "    max_boost = def_times[bench_name] - best_e2e_times[bench_name]\n",
    "    boost_percentage = 100 * boost / max_boost\n",
    "    learning_time = learning_times[bench_name][settings]\n",
    "    \n",
    "    return {\n",
    "        \"`disable_scans`\": settings.disable_scans,\n",
    "        \"`disable_joins`\": settings.disable_joins,\n",
    "        \"`decrease_dop`\": settings.decrease_dop,\n",
    "        \"`disable_inl`\": settings.disable_inl,\n",
    "        \"`use_joined_search`\": settings.use_joined_search,\n",
    "        \"E2E Time (sec)\": round(e2e_time, 1),\n",
    "        \"Boost (% of optimum)\": round(boost_percentage, 1),\n",
    "        \"Learning Time (sec)\": round(learning_time, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = float(\"inf\")\n",
    "\n",
    "for bench_name in cached_oracles:\n",
    "    settings_list = [\n",
    "        ExtendedSearchingSettings(disable_scans=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_scans=True, disable_joins=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_inl=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_scans=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_scans=True, disable_joins=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_inl=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, disable_inl=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, disable_scans=True, disable_inl=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, disable_scans=True, use_joined_search=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_inl=True, use_joined_search=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, use_joined_search=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_joins=True, disable_inl=True, use_joined_search=True, decrease_dop=True, max_iter=MAX_ITER),\n",
    "        ExtendedSearchingSettings(disable_scans=True, disable_joins=True, disable_inl=True, decrease_dop=True, use_joined_search=True, max_iter=MAX_ITER),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for settings in settings_list:\n",
    "        result = evaluate_settings(settings, bench_name)\n",
    "        results.append(result)\n",
    "    pd.DataFrame(results).to_csv(f\"{ARTIFACTS_PATH}/{bench_name}_basic_settings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Which moves are the most important to get high boost*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which of these techniques are the most effective, we will introduce a *score* for the search parameters $x$ similar to the F-Score -- this metric balances between the proportion of the boost obtained from the maximum possible acceleration and the proportion of saved training time:\n",
    "\n",
    "\n",
    "$$\\text{score}_{\\beta}(\\text{x}) = F_{\\beta}(\\text{boost\\_coeff}(\\text{x}), \\text{learning\\_coeff}(\\text{x}))$$\n",
    "\n",
    "где $\\text{boost\\_coeff}(\\text{x}) = \\frac{\\text{max\\_possible\\_boost}}{\\text{learning\\_time(x)}}$ и  $\\text{learning\\_coeff}(\\text{x}) = \\frac{\\text{max\\_possible\\_time} - \\text{learning\\_time}(x)}{\\text{max\\_possible\\_time}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_settings(bench_name, condition=None, beta=2):\n",
    "    max_learning_time = max(learning_times[bench_name].values())\n",
    "    max_speedup = def_times[bench_name] - best_e2e_times[bench_name]\n",
    "    best_score, best_settings = float(\"-inf\"), None\n",
    "    \n",
    "    for settings in settings_pool:\n",
    "        if condition and not condition(settings):\n",
    "            continue\n",
    "        saved_learning_time = max_learning_time - learning_times[bench_name][settings]\n",
    "        learning_coef = saved_learning_time / max_learning_time\n",
    "        boost = def_times[bench_name] - e2e_times[bench_name][settings]\n",
    "        assert boost >= 0, (boost, settings)\n",
    "        boost_coef = boost / max_speedup\n",
    "        score = (1 + beta ** 2) * learning_coef * boost_coef / (beta ** 2 * learning_coef + boost_coef)\n",
    "        if score > best_score:\n",
    "            best_score, best_settings = score, settings\n",
    "\n",
    "    speedup = def_times[bench_name] - e2e_times[bench_name][best_settings]\n",
    "    speedup_coef = speedup / max_speedup \n",
    "    learning_time = learning_times[bench_name][best_settings]\n",
    "\n",
    "    n_tried_states, n_seen_plans, n_plans = 0, 0, 0\n",
    "    all_states = [SearchingState(hintset, dop) for dop in DOPS for hintset in HINTSETS]    \n",
    "    oracle = cached_oracles[bench_name]\n",
    "    queries = oracle.get_query_names()\n",
    "\n",
    "    for query_name in queries:\n",
    "        explorer = SequentialQueryExplorer(query_name=query_name, oracle=oracle, settings=best_settings)\n",
    "        _ = explorer.run()\n",
    "        n_tried_states += len(set(explorer.tried_states))\n",
    "        n_seen_plans += len(explorer.seen_plans)\n",
    "        n_plans += len(set([get_full_plan(explorer._get_explain_plan(st)) for st in all_states]))\n",
    "\n",
    "    best_settings = best_settings._asdict()\n",
    "    return {\n",
    "        \"Beta\": beta,\n",
    "        \"Boost (% of optimum)\": round(100 * speedup_coef, 1),\n",
    "        \"Learning Time (sec)\": round(learning_time, 1),\n",
    "        \"Visited States\": f\"{n_tried_states}/{len(queries) * len(all_states)}\",\n",
    "        \"Visited Plans\": f\"{n_seen_plans}/{n_plans}\",\n",
    "        \"`disable_joins`\": best_settings[\"disable_joins\"],\n",
    "        \"`disable_scans`\": best_settings[\"disable_scans\"],\n",
    "        \"`decrease_dop`\": best_settings[\"decrease_dop\"],\n",
    "        \"`use_joined_search`\": best_settings[\"use_joined_search\"],\n",
    "        \"`disable_inl`\": best_settings[\"disable_inl\"],\n",
    "        \"`relative_boost_threshold`\": best_settings[\"relative_boost_threshold\"],\n",
    "        \"`max_iter`\": best_settings[\"max_iter\"],\n",
    "        \"`avoid_duplicates`\": best_settings[\"avoid_duplicates\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bench_name in cached_oracles:\n",
    "    results = []\n",
    "    condition = lambda el: not el.prioritize_neighbors\n",
    "    for beta in [1/10, 1/5, 1, 2, 10]:\n",
    "        result = find_best_settings(bench_name, condition=condition, beta=beta)\n",
    "        results.append(result)\n",
    "    pd.DataFrame(results).to_csv(f\"{ARTIFACTS_PATH}/{bench_name}_well_balanced_settings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *How well are we reducing search space via local search procedure?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bench_name in cached_oracles:\n",
    "    results = []\n",
    "    condition = lambda el: el.prioritize_neighbors\n",
    "    for beta in [1/10, 1/5, 1, 2, 10]:\n",
    "        result = find_best_settings(bench_name, condition=condition, beta=beta)\n",
    "        results.append(result)\n",
    "    pd.DataFrame(results).to_csv(f\"{ARTIFACTS_PATH}/{bench_name}_well_balanced_settings_with_priority.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
