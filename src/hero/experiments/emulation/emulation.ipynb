{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "  from google.colab import drive\n",
    "  print(\"Hello, Colab\")\n",
    "  drive.mount(\"/content/drive\")\n",
    "  ROOT_PATH = \"/content/drive/MyDrive/hero\"\n",
    "  os.environ[\"CLEARML_CONFIG_FILE\"] = f\"{ROOT_PATH}/clearml.conf\"\n",
    "elif \"PAPERSPACE_CLUSTER_ID\" in os.environ:\n",
    "  print(\"Hello, Paperspace\")\n",
    "  ROOT_PATH = \"/notebooks/hero\"\n",
    "  os.environ[\"CLEARML_CONFIG_FILE\"] = f\"{ROOT_PATH}/clearml.conf\"\n",
    "else:\n",
    "  print(\"Hello, Local PC\")\n",
    "  ROOT_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "BTCNN_PATH = os.path.join(ROOT_PATH, \"btcnn/src/btcnn\")\n",
    "HBO_BENCH_PATH = os.path.join(ROOT_PATH, \"hbo_bench/src/hbo_bench\")\n",
    "EXPERIMENT_PATH = os.getcwd()\n",
    "ARTIFACTS_PATH = os.path.join(EXPERIMENT_PATH, \"artifacts\")\n",
    "\n",
    "BTCNN_PATH = os.path.join(ROOT_PATH, \"btcnn/src/btcnn\")\n",
    "HBO_BENCH_PATH = os.path.join(ROOT_PATH, \"hbo_bench/src/hbo_bench\")\n",
    "EXPERIMENT_PATH = os.getcwd()\n",
    "ARTIFACTS_PATH = os.path.join(EXPERIMENT_PATH, \"artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from json import dump, load\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from hero.hero import Hero\n",
    "from hero.wrappers import ORACLES_DICT, initialize_oracles, _get_e2e_time, _get_execution_time, _get_planning_time, _get_logical_tree\n",
    "from hero.neural_network import NN, get_bt_regressor\n",
    "from hero.train_utils import load_model\n",
    "from hero.emulation import get_report, emulate_online_learning\n",
    "\n",
    "from hbo_bench.local_search_settings import *\n",
    "from hbo_bench.data_config import DEFAULT_DOP, DEFAULT_HINTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_oracles(HBO_BENCH_PATH, [\"JOB\", \"sample_queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device is {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_workload = ORACLES_DICT[\"JOB\"].get_query_names()\n",
    "sq_workload = ORACLES_DICT[\"sample_queries\"].get_query_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideal Case (all plans are in train data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Dop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 500\n",
    "\n",
    "# job_ideal_model = NN(\n",
    "#     fit_settings=ALL_SS, \n",
    "#     inference_settings=EMPTY_SS, \n",
    "#     model=get_bt_regressor(\"job_ideal_model\", DEVICE),\n",
    "#     path_to_save=f\"{EXPERIMENT_PATH}/models/job_ideal_model.pth\"\n",
    "# )\n",
    "# job_ideal_model.fit(job_workload, epochs=epochs)\n",
    "job_ideal_model = load_model(DEVICE, f\"{EXPERIMENT_PATH}/models/job_ideal_model.pth\", get_bt_regressor(\"none\", DEVICE))\n",
    "\n",
    "# sq_ideal_model = NN(\n",
    "#     fit_settings=ALL_SS, \n",
    "#     inference_settings=EMPTY_SS, \n",
    "#     model=get_bt_regressor(\"sq_ideal_model\", DEVICE),\n",
    "#     path_to_save=f\"{EXPERIMENT_PATH}/models/sq_ideal_model.pth\"\n",
    "# )\n",
    "# sq_ideal_model.fit(sq_workload, epochs=epochs)\n",
    "sq_ideal_model = load_model(DEVICE, f\"{EXPERIMENT_PATH}/models/sq_ideal_model.pth\", get_bt_regressor(\"none\", DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_df(df):\n",
    "    df[\"ex boost (% of opt)\"] = 100 * (df[\"def_ex\"] - df[\"custom_ex\"]) / (df[\"def_ex\"] - df[\"opt_ex\"])\n",
    "    df[\"e2e boost (% of opt)\"] = 100 * (df[\"def_e2e\"] - df[\"custom_e2e\"]) / (df[\"def_e2e\"] - df[\"opt_e2e\"])\n",
    "    df[\"e2e boost (%)\"] = 100 * (df[\"def_e2e\"] - df[\"custom_e2e\"]) / df[\"def_e2e\"]\n",
    "    \n",
    "    columns = [\n",
    "        \"model\", \n",
    "        \"searching_settings\", \n",
    "        \"workload\", \n",
    "        \"e2e boost (%)\", \n",
    "        \"e2e boost (% of opt)\", \n",
    "        \"ex boost (% of opt)\", \n",
    "        \"n_timeouts (%)\", \n",
    "        \"n_real_degradations (%)\",\n",
    "        \"custom_e2e\", \n",
    "        \"custom_ex\", \n",
    "        \"custom_inference\", \n",
    "        \"only_def_dop\", \n",
    "    ]\n",
    "    \n",
    "    def count_real_degradations(predictions):\n",
    "        return sum(\n",
    "            _get_e2e_time(q_n, hs, dop, False) > 1.1 * _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP, False)\n",
    "            for q_n, hs, dop in predictions\n",
    "        )\n",
    "    sizes = df[\"predictions\"].apply(lambda el: len(el))\n",
    "    df[\"n_timeouts (%)\"] = 100 * df[\"n_timeouts\"].apply(lambda el: int(el)) / sizes\n",
    "    df[\"n_real_degradations (%)\"] = 100 * df[\"predictions\"].apply(count_real_degradations) / sizes\n",
    "    df = df[columns]\n",
    "    return df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss_and_descrs = [\n",
    "#     (GREEDY_DEF_DOP_SS, \"greedy\"), \n",
    "#     (PRUNED_GREEDY_DEF_DOP_SS, \"pruned greedy\"), \n",
    "#     (LOCAL_DEF_DOP_SS, \"local\"),\n",
    "#     (PRUNED_LOCAL_DEF_DOP_SS, \"pruned local\"),\n",
    "#     (ALL_DEF_DOP_SS, \"exhaustive\")\n",
    "# ]\n",
    "\n",
    "# def_dop_ideal_reports = []\n",
    "# for ss, ss_descr in ss_and_descrs:\n",
    "#     ideal_job_nn_model = NN(fit_settings=EMPTY_SS, inference_settings=ss, model=get_bt_regressor(\"ideal_job\", DEVICE))\n",
    "#     ideal_job_nn_model.model = load_model(device=DEVICE, path=f\"{EXPERIMENT_PATH}/models/job_ideal_model.pth\", model=ideal_job_nn_model.model)\n",
    "#     def_dop_ideal_reports.append(get_report(ideal_job_nn_model, \"NN\", job_workload, \"JOB\", ss, ss_descr, only_def_dop=True))\n",
    "\n",
    "#     ideal_job_hero_model = Hero(fit_settings=ss)\n",
    "#     ideal_job_hero_model.fit(job_workload)\n",
    "#     def_dop_ideal_reports.append(get_report(ideal_job_hero_model, \"Hero\", job_workload, \"JOB\", ss, ss_descr, only_def_dop=True))\n",
    "    \n",
    "#     ideal_sq_nn_model = NN(fit_settings=EMPTY_SS, inference_settings=ss, model=get_bt_regressor(\"ideal_sq\", DEVICE))\n",
    "#     ideal_sq_nn_model.model = load_model(device=DEVICE, path=f\"{EXPERIMENT_PATH}/models/sq_ideal_model.pth\", model=ideal_sq_nn_model.model)\n",
    "#     def_dop_ideal_reports.append(get_report(ideal_sq_nn_model, \"NN\", sq_workload, \"SQ\", ss, ss_descr, only_def_dop=True))\n",
    "\n",
    "#     ideal_sq_hero_model = Hero(fit_settings=ss)\n",
    "#     ideal_sq_hero_model.fit(sq_workload)\n",
    "#     def_dop_ideal_reports.append(get_report(ideal_sq_hero_model, \"Hero\", sq_workload, \"SQ\", ss, ss_descr, only_def_dop=True))\n",
    "\n",
    "# with open(f\"{ARTIFACTS_PATH}/def_dop_ideal_reports.json\", \"w\") as f:\n",
    "#     dump(def_dop_ideal_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ARTIFACTS_PATH}/def_dop_ideal_reports.json\", \"r\") as f:\n",
    "    def_dop_df = extend_df(pd.DataFrame(load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_dop_df[(def_dop_df[\"workload\"] == \"JOB\")].sort_values(by=\"e2e boost (% of opt)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_dop_df[(def_dop_df[\"workload\"] == \"SQ\")].sort_values(by=\"e2e boost (% of opt)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Dop's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss_and_descrs = [\n",
    "#     (GREEDY_SS, \"greedy\"), \n",
    "#     (PRUNED_GREEDY_SS, \"pruned greedy\"), \n",
    "#     (LOCAL_SS, \"local\"),\n",
    "#     (PRUNED_LOCAL_SS, \"pruned local\"),\n",
    "#     (ALL_SS, \"exhaustive\")\n",
    "# ]\n",
    "\n",
    "# all_dops_ideal_reports = []\n",
    "# for ss, ss_descr in ss_and_descrs:\n",
    "#     ideal_job_nn_model = NN(fit_settings=EMPTY_SS, inference_settings=ss, model=get_bt_regressor(\"ideal_job\", DEVICE))\n",
    "#     ideal_job_nn_model.model = load_model(device=DEVICE, path=f\"{EXPERIMENT_PATH}/models/job_ideal_model.pth\", model=ideal_job_nn_model.model)\n",
    "#     all_dops_ideal_reports.append(get_report(ideal_job_nn_model, \"NN\", job_workload, \"JOB\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#     ideal_job_hero_model = Hero(fit_settings=ss)\n",
    "#     ideal_job_hero_model.fit(job_workload)\n",
    "#     all_dops_ideal_reports.append(get_report(ideal_job_hero_model, \"Hero\", job_workload, \"JOB\", ss, ss_descr, only_def_dop=False))\n",
    "    \n",
    "#     ideal_sq_nn_model = NN(fit_settings=EMPTY_SS, inference_settings=ss, model=get_bt_regressor(\"ideal_sq\", DEVICE))\n",
    "#     ideal_sq_nn_model.model = load_model(device=DEVICE, path=f\"{EXPERIMENT_PATH}/models/sq_ideal_model.pth\", model=ideal_sq_nn_model.model)\n",
    "#     all_dops_ideal_reports.append(get_report(ideal_sq_nn_model, \"NN\", sq_workload, \"SQ\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#     ideal_sq_hero_model = Hero(fit_settings=ss)\n",
    "#     ideal_sq_hero_model.fit(sq_workload)\n",
    "#     all_dops_ideal_reports.append(get_report(ideal_sq_hero_model, \"Hero\", sq_workload, \"SQ\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "# with open(f\"{ARTIFACTS_PATH}/all_dops_ideal_reports.json\", \"w\") as f:\n",
    "#     dump(all_dops_ideal_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ARTIFACTS_PATH}/all_dops_ideal_reports.json\", \"r\") as f:\n",
    "    all_dops_df = extend_df(pd.DataFrame(load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dops_df[(all_dops_df[\"workload\"] == \"JOB\")].sort_values(by=\"e2e boost (% of opt)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dops_df[(all_dops_df[\"workload\"] == \"SQ\")].sort_values(by=\"e2e boost (% of opt)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even in the ideal scenario, the NN loses a bit, mainly due to the longer inference time. Moreover, it sometimes leads to degradations and even `T/O` (this probably happens on small queries).\n",
    "\n",
    "The advantage of a `PRUNED LOCAL` strategy is also evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Scenario\n",
    "\n",
    "Collecting train data during online optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for workload, workload_name in [(job_workload, \"JOB\"), (sq_workload, \"SQ\")]:\n",
    "#     def_dop_list_online_reports = []\n",
    "#     all_dops_list_online_reports = []\n",
    "\n",
    "#     epochs, iterations = 300, 25\n",
    "#     for ss, ss_descr in [\n",
    "#         (GREEDY_DEF_DOP_SS, \"GREEDY\"),\n",
    "#         (PRUNED_GREEDY_DEF_DOP_SS, \"PRUNED GREEDY\"),\n",
    "#         (LOCAL_DEF_DOP_SS, \"LOCAL\"),\n",
    "#         (PRUNED_LOCAL_DEF_DOP_SS, \"PRUNED LOCAL\"),\n",
    "#         (ALL_DEF_DOP_SS, \"EXHAUSTIVE\"),\n",
    "#     ]:\n",
    "#         def_dop_list_online_reports.append(emulate_online_learning(\"NN\", workload, workload_name, ss, ss_descr, True, True, epochs, iterations, None, DEVICE))\n",
    "\n",
    "#     for ss, ss_descr in [\n",
    "#         (GREEDY_SS, \"GREEDY\"),\n",
    "#         (PRUNED_GREEDY_SS, \"PRUNED GREEDY\"),\n",
    "#         (LOCAL_SS, \"LOCAL\"),\n",
    "#         (PRUNED_LOCAL_SS, \"PRUNED LOCAL\"),\n",
    "#         (ALL_SS, \"EXHAUSTIVE\"),\n",
    "#     ]:          \n",
    "#         all_dops_list_online_reports.append(emulate_online_learning(\"NN\", workload, workload_name, ss, ss_descr, False, True, epochs, iterations, None, DEVICE))\n",
    "    \n",
    "#     with open(f\"{ARTIFACTS_PATH}/{workload_name}_def_dop_list_online_reports.json\", \"w\") as f:\n",
    "#         dump(def_dop_list_online_reports, f)\n",
    "#     with open(f\"{ARTIFACTS_PATH}/{workload_name}_all_dops_list_online_reports.json\", \"w\") as f:\n",
    "#         dump(all_dops_list_online_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(\n",
    "    list_reports,\n",
    "    figsize=(12, 6),\n",
    "    label_fontsize=10, \n",
    "    linewidth_small=1, \n",
    "    linewidth_big=2, \n",
    "    markersize=5, \n",
    "    markeredgewidth=5,\n",
    "    linestyle_small='--',\n",
    "    linestyle_big='-', \n",
    "    alpha_small=0.4, \n",
    "    alpha_big=1.0, \n",
    "    xlabel=\"iteration\", \n",
    "    ylabel=\"Time (sec)\", \n",
    "    tick_label_fontsize=12, \n",
    "    legend_fontsize=10, \n",
    "    save_name=None    \n",
    "):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_palette(\"deep\")\n",
    "    colors = sns.color_palette(\"deep\", len(list_reports[0]) + 2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    x_values = np.arange(len(list_reports[0]))\n",
    "\n",
    "    for i, report in enumerate(list_reports):\n",
    "        if \"GREEDY\" in report[0][\"searching_settings\"]:\n",
    "            marker = \"^\"\n",
    "        elif \"LOCAL\" in report[0][\"searching_settings\"]:\n",
    "            marker = \"x\"\n",
    "        else:\n",
    "            marker = \"o\"\n",
    "        color = colors[i]\n",
    "        ax.plot(\n",
    "            x_values, \n",
    "            [el[\"custom_ex\"] for el in report], \n",
    "            marker=marker,\n",
    "            markersize=markersize,\n",
    "            markeredgewidth=markeredgewidth,\n",
    "            linewidth=linewidth_small, \n",
    "            linestyle=linestyle_small, \n",
    "            color=color, \n",
    "            label=f'{report[0][\"searching_settings\"]} EX'\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_values, \n",
    "            [el[\"custom_e2e\"] for el in report], \n",
    "            marker=marker, \n",
    "            linewidth=linewidth_big, \n",
    "            markersize=markersize, \n",
    "            markeredgewidth=markeredgewidth,\n",
    "            linestyle=linestyle_big, \n",
    "            color=color, \n",
    "            label=f'{report[0][\"searching_settings\"]} E2E'\n",
    "        )\n",
    "\n",
    "    for i, metric in enumerate([\"opt\", \"def\"], start=1):\n",
    "        for key, linewidth, linestyle, alpha in zip(\n",
    "            [\"ex\", \"e2e\"], \n",
    "            [linewidth_small, linewidth_big], \n",
    "            [linestyle_small, linestyle_big], \n",
    "            [alpha_small, alpha_big]\n",
    "        ):\n",
    "            label = \"Optimum\" if metric == \"opt\" else \"Default\"\n",
    "            label += \" Ex\" if key == \"ex\" else \" E2E\"\n",
    "            value = list_reports[0][0][f\"{metric}_{key}\"]\n",
    "            plt.plot(\n",
    "                [0, len(list_reports[0])-1], \n",
    "                [value, value], \n",
    "                linewidth=linewidth, \n",
    "                color=colors[-i], \n",
    "                alpha=alpha, \n",
    "                linestyle=linestyle, \n",
    "                label=label\n",
    "            )\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), fontsize=legend_fontsize, loc=\"upper right\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_xticks(range(len(list_reports[0])))\n",
    "    ax.set_ylim(bottom=list_reports[0][0][f\"opt_ex\"] - 10)\n",
    "\n",
    "    plt.xlabel(xlabel, fontsize=label_fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=label_fontsize)\n",
    "\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.2)\n",
    "\n",
    "    if save_name:\n",
    "        plt.savefig(f\"{ARTIFACTS_PATH}/{save_name}\", format='svg', dpi=300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for workload, workload_name in [(job_workload, \"JOB\"), (sq_workload, \"SQ\")]:\n",
    "    with open(f\"{ARTIFACTS_PATH}/{workload_name}_def_dop_list_online_reports.json\", \"r\") as f:\n",
    "        def_dop_list_online_reports = load(f)\n",
    "        visualise(def_dop_list_online_reports, figsize=(16, 8), save_name=f\"{workload_name}_def_dop_online.svg\")\n",
    "\n",
    "    with open(f\"{ARTIFACTS_PATH}/{workload_name}_all_dops_list_online_reports.json\", \"r\") as f:\n",
    "        all_dops_list_online_reports = load(f)\n",
    "        visualise(all_dops_list_online_reports, figsize=(16, 8), save_name=f\"{workload_name}_all_dops_online.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, as the search space expands, the exhaustive algorithms stop working (at least on `JOB`). The superiority of the `Local Search` algorithm and the pruning procedure is also evident.\n",
    "\n",
    "Moreover, it did not always converge to the optimum even in 25 iterations - this tells us that it makes sense to take the learning procedure offline (as it is done in `Hero`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow_reports, fast_reports = [], []\n",
    "\n",
    "# epochs = 300\n",
    "# for workload, workload_name in [(job_workload, \"JOB\"), (sq_workload, \"SQ\")]:\n",
    "#     workload = [q_n for q_n in workload if _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) > 1]\n",
    "\n",
    "#     slow_time_treshold = np.quantile([_get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) for q_n in workload], .5)\n",
    "#     slow_train = [q_n for q_n in workload if _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) > slow_time_treshold]\n",
    "#     slow_test = [q_n for q_n in workload if _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) <= slow_time_treshold]\n",
    "#     assert len(slow_train) + len(slow_test) == len(workload)\n",
    "#     slow_nnmodel = NN(fit_settings=ALL_SS, inference_settings=EMPTY_SS, model=get_bt_regressor(\"dummy\", DEVICE))\n",
    "#     slow_nnmodel.fit(slow_train, epochs)\n",
    "\n",
    "#     fast_time_treshold = np.quantile([_get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) for q_n in workload], .5)\n",
    "#     fast_train = [q_n for q_n in workload if _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) < fast_time_treshold]\n",
    "#     fast_test = [q_n for q_n in workload if _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP) >= fast_time_treshold]\n",
    "#     assert len(fast_train) + len(fast_test) == len(workload)\n",
    "#     fast_nnmodel = NN(fit_settings=ALL_SS, inference_settings=EMPTY_SS, model=get_bt_regressor(\"dummy\", DEVICE))\n",
    "#     fast_nnmodel.fit(fast_train, epochs)\n",
    "\n",
    "#     for ss, ss_descr in [\n",
    "#         (GREEDY_SS, \"GREEDY\"),\n",
    "#         (PRUNED_GREEDY_SS, \"PRUNED GREEDY\"),\n",
    "#         (LOCAL_SS, \"LOCAL\"),\n",
    "#         (PRUNED_LOCAL_SS, \"PRUNED LOCAL\"),\n",
    "#         (ALL_SS, \"EXHAUSTIVE\"),\n",
    "#     ]:\n",
    "#         slow_reports.append(get_report(slow_nnmodel, \"NN\", slow_train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#         slow_reports.append(get_report(slow_nnmodel, \"NN\", slow_test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "#         slow_heromodel = Hero(ss)\n",
    "#         slow_heromodel.fit(slow_train)\n",
    "#         slow_reports.append(get_report(slow_heromodel, \"Hero\", slow_train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#         slow_reports.append(get_report(slow_heromodel, \"Hero\", slow_test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#         fast_reports.append(get_report(fast_nnmodel, \"NN\", fast_train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#         fast_reports.append(get_report(fast_nnmodel, \"NN\", fast_test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "#         fast_heromodel = Hero(ss)\n",
    "#         fast_heromodel.fit(fast_train)\n",
    "#         fast_reports.append(get_report(fast_heromodel, \"Hero\", fast_train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#         fast_reports.append(get_report(fast_heromodel, \"Hero\", fast_test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#         with open(f\"{ARTIFACTS_PATH}/{workload_name}_slow_reports.json\", \"w\") as f:\n",
    "#             dump(slow_reports, f)\n",
    "#         with open(f\"{ARTIFACTS_PATH}/{workload_name}_fast_reports.json\", \"w\") as f:\n",
    "#             dump(fast_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ARTIFACTS_PATH}/JOB_slow_reports.json\", \"r\") as f:\n",
    "    job_slow_df = extend_df(pd.DataFrame(load(f)))\n",
    "with open(f\"{ARTIFACTS_PATH}/JOB_fast_reports.json\", \"r\") as f:\n",
    "    job_fast_df = extend_df(pd.DataFrame(load(f)))\n",
    "with open(f\"{ARTIFACTS_PATH}/SQ_slow_reports.json\", \"r\") as f:\n",
    "    sq_slow_df = extend_df(pd.DataFrame(load(f)))\n",
    "with open(f\"{ARTIFACTS_PATH}/SQ_fast_reports.json\", \"r\") as f:\n",
    "    sq_fast_df = extend_df(pd.DataFrame(load(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slow $\\rightarrow$ fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_slow_df[(job_slow_df[\"workload\"] == \"JOB[train]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_slow_df[(job_slow_df[\"workload\"] == \"JOB[test]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_slow_df[(sq_slow_df[\"workload\"] == \"SQ[train]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_slow_df[(sq_slow_df[\"workload\"] == \"SQ[test]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that `Hero` is always better on `train`, is safer on `test` (`SQ`), but sometimes it misses possible boost (`JOB`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast $\\rightarrow$ slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_fast_df[(job_fast_df[\"workload\"] == \"JOB[train]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_fast_df[(job_fast_df[\"workload\"] == \"JOB[test]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_fast_df[(sq_fast_df[\"workload\"] == \"SQ[train]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_fast_df[(sq_fast_df[\"workload\"] == \"SQ[test]\")].sort_values(by=\"e2e boost (%)\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions.**\\\n",
    "We can perfectly see the signs of **overfitting** in `Hero` (which is what we wanted) - almost perfect performance on training and safe, rare predictions on the test. On new data, we stop predicting, so we don't get degradation.\n",
    "\n",
    "The NN approach, on the other hand, has the advantage of **being able to generalise knowledge** to new queries. Thus, we can see that generalisation from fast queries on `SQ` is quite effective - we can speed up their execution by 2 times (even taking into account that we get degradations in 17% of cases). However, prediction on new queries can also bring regression, which is observed from generalising over slow queries.\n",
    "\n",
    "P.S. It is probably easier to generalise knowledge from short queries to long queries because parts of their efficient long query plans are quite fast to execute and must have already been encountered in fast query plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traintest_split(groups, ratio, seed=42, debug=False):\n",
    "    train, test = [], []\n",
    "    for group in groups:\n",
    "        random.seed(seed)\n",
    "        random.shuffle(group)\n",
    "        pivot = int(len(group) * ratio)\n",
    "        train += group[:pivot]\n",
    "        test += group[pivot:]\n",
    "        if debug: \n",
    "            print(f\"{group} -> {group[:pivot]}, {group[pivot:]}\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 300\n",
    "# for workload, workload_name in [(job_workload, \"JOB\")]:\n",
    "    \n",
    "#     logical_trees_to_queries = defaultdict(list)\n",
    "#     for q_n in workload:\n",
    "#         logical_trees_to_queries[_get_logical_tree(q_n, DEFAULT_HINTSET, DEFAULT_DOP)].append(q_n)\n",
    "\n",
    "#     structure_reports = []\n",
    "#     for seed in range(10):\n",
    "#         train, test = get_traintest_split([v for v in logical_trees_to_queries.values() if len(v) > 1], ratio=0.5, seed=seed)\n",
    "#         nnmodel = NN(fit_settings=ALL_SS, inference_settings=ss, model=get_bt_regressor(\"dummy\", DEVICE))\n",
    "#         nnmodel.fit(train, epochs)\n",
    "\n",
    "#         for ss, ss_descr in [\n",
    "#             (GREEDY_SS, \"GREEDY\"),\n",
    "#             (PRUNED_GREEDY_SS, \"PRUNED GREEDY\"),\n",
    "#             (LOCAL_SS, \"LOCAL\"),\n",
    "#             (PRUNED_LOCAL_SS, \"PRUNED LOCAL\"),\n",
    "#             (ALL_SS, \"EXHAUSTIVE\"),\n",
    "#         ]:\n",
    "#             structure_reports.append(get_report(nnmodel, \"NN\", train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#             structure_reports.append(get_report(nnmodel, \"NN\", test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#             heromodel = Hero(ss)\n",
    "#             heromodel.fit(train)\n",
    "#             structure_reports.append(get_report(heromodel, \"Hero\", train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#             structure_reports.append(get_report(heromodel, \"Hero\", test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "        \n",
    "#     with open(f\"{ARTIFACTS_PATH}/{workload_name}_structure_reports.json\", \"w\") as f:\n",
    "#         dump(structure_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(reports):\n",
    "    df = pd.DataFrame(reports)\n",
    "    df[\"ex boost (% of opt)\"] = 100 * (df[\"def_ex\"] - df[\"custom_ex\"]) / (df[\"def_ex\"] - df[\"opt_ex\"])\n",
    "    df[\"e2e boost (% of opt)\"] = 100 * (df[\"def_e2e\"] - df[\"custom_e2e\"]) / (df[\"def_e2e\"] - df[\"opt_e2e\"])\n",
    "    df[\"e2e boost (%)\"] = 100 * (df[\"def_e2e\"] - df[\"custom_e2e\"]) / df[\"def_e2e\"]\n",
    "\n",
    "    def count_real_degradations(predictions):\n",
    "        return sum(\n",
    "            _get_e2e_time(q_n, hs, dop) > 1.1 * _get_e2e_time(q_n, DEFAULT_HINTSET, DEFAULT_DOP)\n",
    "            for q_n, hs, dop in predictions\n",
    "        )\n",
    "    \n",
    "    sizes = df[\"predictions\"].apply(lambda el: len(el))\n",
    "    df[\"n_timeouts (%)\"] = 100 * df[\"n_timeouts\"].apply(lambda el: int(el)) / sizes\n",
    "    df[\"n_real_degradations (%)\"] = 100 * df[\"predictions\"].apply(count_real_degradations) / sizes\n",
    "\n",
    "    experiment_cols = [\"model\", \"workload\", \"searching_settings\"]\n",
    "    value_cols = [\n",
    "        \"e2e boost (%)\",\n",
    "        \"e2e boost (% of opt)\", \n",
    "        \"ex boost (% of opt)\", \n",
    "        \"n_timeouts (%)\", \n",
    "        \"n_real_degradations (%)\",\n",
    "        \"custom_e2e\", \n",
    "        \"custom_ex\", \n",
    "        \"custom_inference\",    \n",
    "    ]\n",
    "\n",
    "    df = df[experiment_cols + value_cols]\n",
    "\n",
    "    grouped_df = df.groupby(experiment_cols).agg(\n",
    "        {\n",
    "            col: [\"mean\", \"std\"]\n",
    "            for col in value_cols\n",
    "        }\n",
    "    ).reset_index()\n",
    "\n",
    "    def combine_mean_std(row):\n",
    "        return f\"{row['mean']:.1f} ± {row['std']:.1f}\"\n",
    "\n",
    "    for col in value_cols:\n",
    "        grouped_df[(col, 'mean ± std')] = grouped_df[col].apply(combine_mean_std, axis=1)\n",
    "\n",
    "    grouped_df.columns = [' '.join(col).strip() for col in grouped_df.columns.values]\n",
    "    columns_to_keep = experiment_cols + [f\"{col} mean\" for col in value_cols] + [f\"{col} std\" for col in value_cols]\n",
    "    grouped_df = grouped_df[columns_to_keep]\n",
    "    grouped_df.columns = experiment_cols + [f\"mean {col}\" for col in value_cols] + [f\"std {col}\" for col in value_cols]\n",
    "    return grouped_df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ARTIFACTS_PATH}/JOB_structure_reports.json\", \"r\") as f:\n",
    "    job_structure_df = aggregate_results(load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_cols = [\n",
    "    \"model\", \n",
    "    \"searching_settings\",\n",
    "    \"mean e2e boost (%)\",\n",
    "    \"mean e2e boost (% of opt)\",\n",
    "    \"mean ex boost (% of opt)\",\n",
    "    \"mean n_timeouts (%)\",\n",
    "    \"mean n_real_degradations (%)\",    \n",
    "    \"std e2e boost (%)\",\n",
    "    \"std e2e boost (% of opt)\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_structure_df[(job_structure_df[\"workload\"] == \"JOB[train]\")].sort_values(by=\"mean e2e boost (% of opt)\", ascending=False)[interesting_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_structure_df[(job_structure_df[\"workload\"] == \"JOB[test]\")].sort_values(by=\"mean e2e boost (% of opt)\", ascending=False)[interesting_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that generalisation in the presence of structure is efficient (boost up to 36% on JOB and 70% on `SQ`), but even though the structure of the logical plans was repeated, about 20% of the predictions either slowed down the query or led them to `T/O`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 300\n",
    "# for workload, workload_name in [(job_workload, \"JOB\"), (sq_workload, \"SQ\")]:\n",
    "#     random_split_reports = []\n",
    "#     for seed in range(10):\n",
    "#         train, test = get_traintest_split([workload], ratio=0.5, seed=seed)\n",
    "#         nnmodel = NN(fit_settings=ALL_SS, inference_settings=ss, model=get_bt_regressor(\"dummy\", DEVICE))\n",
    "#         nnmodel.fit(train, epochs)\n",
    "\n",
    "#         for ss, ss_descr in [\n",
    "#             (GREEDY_SS, \"GREEDY\"),\n",
    "#             (PRUNED_GREEDY_SS, \"PRUNED GREEDY\"),\n",
    "#             (LOCAL_SS, \"LOCAL\"),\n",
    "#             (PRUNED_LOCAL_SS, \"PRUNED LOCAL\"),\n",
    "#             (ALL_SS, \"EXHAUSTIVE\"),\n",
    "#         ]:\n",
    "#             random_split_reports.append(get_report(nnmodel, \"NN\", train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#             random_split_reports.append(get_report(nnmodel, \"NN\", test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "\n",
    "#             heromodel = Hero(ss)\n",
    "#             heromodel.fit(train)\n",
    "#             random_split_reports.append(get_report(heromodel, \"Hero\", train, f\"{workload_name}[train]\", ss, ss_descr, only_def_dop=False))\n",
    "#             random_split_reports.append(get_report(heromodel, \"Hero\", test, f\"{workload_name}[test]\", ss, ss_descr, only_def_dop=False))\n",
    "        \n",
    "#     with open(f\"{ARTIFACTS_PATH}/{workload_name}_random_split_reports.json\", \"w\") as f:\n",
    "#         dump(random_split_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{ARTIFACTS_PATH}/JOB_random_split_reports.json\", \"r\") as f:\n",
    "    job_random_split_df = aggregate_results(load(f))\n",
    "with open(f\"{ARTIFACTS_PATH}/SQ_random_split_reports.json\", \"r\") as f:\n",
    "    sq_random_split_df = aggregate_results(load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_random_split_df[(sq_random_split_df[\"workload\"] == \"SQ[test]\")].sort_values(by=\"mean e2e boost (%)\", ascending=False)[interesting_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_random_split_df[(job_random_split_df[\"workload\"] == \"JOB[test]\")].sort_values(by=\"mean e2e boost (%)\", ascending=False)[interesting_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions.**\\\n",
    "We can clearly see that with random partitioning the \"power\" of generalisation drops significantly. We also can see, that the more plans are evaluated by the NN, the greater the probability of observing degradations and regressions (up to 30% `T/O`). But even versions with pruned search slow down queries in about 20% of cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
